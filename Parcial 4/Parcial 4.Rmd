---
title: "Series de tiempo - Parcial 4"
author: "Felipe Lopera & Jhonatan Smith"
date: "2022-10-09"
output: rmdformats::readthedown
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, warning=FALSE, include=FALSE}
require(dplyr)
require(lmtest)
require(tseries)
require(TSA)
require(astsa)
require(tsoutliers)
require(kableExtra)
require(tidyverse)
require(ggplot2)
require(hrbrthemes)
require(tsoutliers)
require(TSstudio)
require(forecast)
require(latticeExtra)
require(datetime)
library(lubridate)
require(forecast)
library(readxl)
require(forecast)
require(readr)
require(janitor)
```


# Base de datos nacimientos hospital 

```{r include=FALSE}

# fn para calcular las raices unitarias y graficas bien chimbita
arroots <- function(object)
{
  if(!("Arima" %in% class(object)) &
     !("ar" %in% class(object)))
    stop("object must be of class Arima or ar")
  if("Arima" %in% class(object))
    parvec <- object$model$phi
  else
    parvec <- object$ar
  if(length(parvec) > 0)
  {
    last.nonzero <- max(which(abs(parvec) > 1e-08))
    if (last.nonzero > 0)
      return(structure(list(
          roots=polyroot(c(1,-parvec[1:last.nonzero])),
          type="AR"),
        class='armaroots'))
  }
  return(structure(list(roots=numeric(0), type="AR"),
    class='armaroots'))
}

# Compute MA roots
maroots <- function(object)
{
  if(!("Arima" %in% class(object)))
    stop("object must be of class Arima")
  parvec <- object$model$theta
  if(length(parvec) > 0)
  {
    last.nonzero <- max(which(abs(parvec) > 1e-08))
    if (last.nonzero > 0)
      return(structure(list(
          roots=polyroot(c(1,parvec[1:last.nonzero])),
          type="MA"),
        class='armaroots'))
  }
  return(structure(list(roots=numeric(0), type="MA"),
    class='armaroots'))
}

plot.armaroots <- function(x, xlab="Real", ylab="Imaginary",
    main=paste("Inverse roots of", x$type,
          "characteristic polynomial"),
    ...)
{
  oldpar <- par(pty='s')
  on.exit(par(oldpar))
  plot(c(-1,1), c(-1,1), xlab=xlab, ylab=ylab,
       type="n", bty="n", xaxt="n", yaxt="n", main=main, ...)
  axis(1, at=c(-1,0,1), line=0.5, tck=-0.025)
  axis(2, at=c(-1,0,1), label=c("-i","0","i"),
    line=0.5, tck=-0.025)
  circx <- seq(-1,1,l=501)
  circy <- sqrt(1-circx^2)
  lines(c(circx,circx), c(circy,-circy), col='gray')
  lines(c(-2,2), c(0,0), col='gray')
  lines(c(0,0), c(-2,2), col='gray')
  if(length(x$roots) > 0)
  {
    inside <- abs(x$roots) > 1
    points(1/x$roots[inside], pch=19, col='black')
    if(sum(!inside) > 0)
      points(1/x$roots[!inside], pch=19, col='red')
  }
}
```

Inicialmente se desea trabajar con un indice. Proporcion de niñas nacidas vs niños nacidos ; es decir:

Hembra/ macho; queremos ver si es igual, menor y si esto tiene una evolucion en el tiempo.

```{r warning=FALSE}
datos <- read.csv("Nacidos_Vivos_en_Hospital_Manuel_Uribe_Angel.csv")
datos$FECHA.NACIMIENTO <- gsub(" \\d+:\\d+:\\d+ .*", "", datos$FECHA.NACIMIENTO)
datos$FECHA.NACIMIENTO <- as.Date(datos$FECHA.NACIMIENTO, format = "%m/%d/%Y")
datos <- datos %>%  mutate(Anio = year(FECHA.NACIMIENTO), semana = week(FECHA.NACIMIENTO)) %>% 
  group_by(Anio, semana) %>% 
  summarise(ratio = sum(SEXO != "MASCULINO")/sum(SEXO == "MASCULINO"))
lambda <- forecast::BoxCox.lambda(datos$ratio)
datos$ratio <- forecast::BoxCox(datos$ratio, lambda)

pacf(datos$ratio)
```

Empezamos mal...

```{r}
acf(datos$ratio)
```

Y terminamos pior. 


```{r}
x = datos$ratio
plot(x, type = "l")
```


Ombe pues bonita si se ve peeero... Y entonces?

```{r}
mod <- forecast::auto.arima(datos$ratio)
summary(mod)
```

Como dijo aquella figura de la tv mexicana; 'Lo sospeché desde un principio'

```{r warning=FALSE}
fit <- mod
par(mfrow=c(1,2))
plot(arroots(fit),main="Inverse AR roots")
plot(maroots(fit),main="Inverse MA roots")
```

Basicamente vale monda este modelo. No el modelo, el problema

¿Que pasó con las raíces? # Maso, oh tu que todo lo sabes. Iluminad a este pobre mortal, pues la luz de la esperanza se escapa ante cada linea de codigo que escribe.

Hipotesis: La naturaleza del problema no responde a un analisis de series temporales. La proporcion de nacimientos de niños vs niñas no varia en el tiempo; no es un dato temporal. 

Nota para smith del futuro: Basicamente, piense en la teoria antes de perder toda la tarde haciendo estas pendejadas buscando soluciones rebuscadas. KISS
# Base de datos cerditos (Yopal)

## Marco teorico: ¿Por qué los cerditos?

![Un lindo cerdito](C:/Users\jhsga\OneDrive\Escritorio\ODINSA\Parcial-4-series-de-tiempo\Parcial 4\tierno.jpg)

Tenga presente que el análisis del consumo cárnico para una población es importante puesto que a las entidades gubernamentales le permite controlar y entender dicho comportamiento para identificar y prever posibles problemas de salud pública o en su defecto, generar políticas para controlar la economía del consumo. Se entiende pues, que un análisis para con el consumo es de vital importancia para los análisis demográficos de una población. 

También, tener un control total sobre la cantidad de cerdos sacrificados, ayuda a las entidades sanitarias a mantener un estándar en dicha producción. Si esto no es regulado, se pueden propagar enfermedades por la mala praxis en la industria.

En el presente análisis, se desea predecir el número total de cabezas porcinas sacrificadas.


# PERO AUN MAS IMPORTANTE:

![Una chuleta](C:/Users\jhsga\OneDrive\Escritorio\ODINSA\Parcial-4-series-de-tiempo\Parcial 4\chuleta.jpg)
El factor económico y sabroso del asunto.. 

## Procesamiento de la base de datos

El primer paso es la lectura de los datos. Dado que los nombres de la serie se encuentran inapropiados para trabajar con ellos, se corrigen los mismos después de leer la base de datos.

```{r message=FALSE, warning=FALSE}

df = read_delim("cerdos.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)
df = clean_names(df)
df %>% names()
```

El primer paso es la lectura de los datos. Dado que los nombres de la serie se encuentran inapropiados para trabajar con ellos, se corrigen los mismos después de leer la base de datos.
La variable año se convierte en 'ano'. Nos gusta ese nombre entonces, así se queda. La base de datos tiene las siguientes variables.

Descripción de las variables en el dataframe:

 *Ano:* Año en el que se toma el registro
 
 *sacrificios_porcinos_machos:* El nombre lo indica, cantidad de sacrificios porcinos machos
 
 *sacrificio_porcinos_hembras:* Cantidad de sacrificios porcinos de hembras
 
 *mes:* Mes en el cual se realizó el sacrificio
 
 *Longitus y latitud:*Ubicacion espacial del lugar de sacrificio 
 
 *sacrificio_totales:* Sacrificios totales porcinos
 
Respecto a la variable 'mes' se encuentra en formato carácter y, representa los meses en español.


```{r}
df$mes %>% unique() # Se verifica que no estén repetidos valores
```
Se procede entonces a crear la variable 'date' que representará la fecha asociada a cada dato.

```{r}
df$mes =as.factor(df$mes)
df$mes %>% levels# Se convierte en factor, cambia el orden
month_id = c(4,8,12,1,2,7,6,3,5,11,10,9)
levels(df$mes) = month_id
df$mes = df$mes %>% as.character()
```
Cuando se aplica la función as.factor, el orden de los mismos cambia. Entonces simplemente, se cambiará los niveles de la variable como factor a un valor numérico, siendo 1 enero, 2 febrero y así sucesivamente. Luego, se transforma en string (Caracter) para obtener finalmente el mes en número.

Para adquirir correctamente el formato en date, se ha de tener un día cualquiera agregado. Se escoge el día 13.

```{r}
df$dia = replicate(length(df$ano), '13')
df$ano = df$ano %>% as.character()

df$date = paste(df$dia,df$mes,df$ano,sep = '-')
df$date = as.Date(df$date, format = '%d-%m-%Y')
# Con esto, se tiene la base de datos lista para trabajar

df = df[order(df$date),] # ordenando por fecha mas vieja
```

## Grafico de la serie

Se procede a graficas las series por Macho, Hembra y Total de sacrificios en orden cronológico.

## Total por Macho y Hembra

```{r}

# --> construct separate plots for each series
obj1 <- xyplot(sacrificios_porcinos_machos ~ date, df, type = "l" , lwd=2)
obj2 <- xyplot(sacrificio_porcinos_hembras ~ date, df, type = "l", lwd=2)
 
# --> Make the plot with second y axis AND legend:
doubleYScale(obj1, obj2, text = c("sacrificios_porcinos_machos", "sacrificio_porcinos_hembras") , add.ylab2 = TRUE)
```

En principio, no parece haber una diferencia significativa de una serie respecto a la otra. Se nota que una de las series está ligeramente por encima de la otra, pero; los patrones de ambas son muy similares.

## Total de sacrificios porcinos


```{r echo=FALSE, message=FALSE, warning=FALSE}

x = df$date
y = df$sacrificio_totales

# plot 

ggplot(df, aes(x=date,y=sacrificio_totales))+
  geom_line(color = '#69b3a2', size = 1.5, alpha = 0.9)+
  theme_ipsum()+
  ggtitle('Total de sacrificios porcinos')

```

La grafica del total de sacrificios porcinos sigue un comportamiento similar a cuando se categoriza por sexo. Ahora, se decide trabajar con la serie del total por simplicidad. 

Ahora, normalmente los cerdos macho poseen un mayor peso dada su contextura, por esto es que; es normal entender que la relación de cantidad totales sacrificadas sea ligeramente mayor por macho que por hembra. Para los intereses del análisis, se hará con el total de cerdos. 

## Primer modelo con auto.arima

Se utiliza esta primera función como un primer acercamiento para entender que se identifica de manera automática.


```{r}
mod1 = auto.arima(df$sacrificio_totales)
mod1 %>% summary()

```

Para este caso puntual, el modelo que sugiere el auto.arima es un ARIMA(0,1,0). ¿Tiene esto sentido?

## Análisis de la ACF y PACF


```{r}
acf(df$sacrificio_totales) 
```

Note que la ACF muestra un decaimiento lento. Por tal motivo, se han de tomar diferencias (Esto indica, d>=1) en el modelo. Se grafica la acf diferenciada.

```{r}
Diferencias.modelo = na.omit(diff(df$sacrificio_totales))
acf(Diferencias.modelo)
```
Note que, al tomar una diferencia, parece haber un corte en el lag 15. Aun así, se podría pensar que es muy poco significativo; dado que una autocorrelación de orden 15 implicaría que los datos se relacionan. Igualmente, que un lag de 8. No se tiene seguridad en la significancia de los lags asociados a la ACF

```{r}
pacf(df$sacrificio_totales)
```

Note que la PACF muestra que no hay autocorrelación parcial en los datos asociados a el sacrificio total. ¿Por qué? Se podría suponer que los datos a priori no parecen responder a una variable temporal. Esto es pues, una sospecha infundada ya sea por el tamaño de la muestra o por la naturaleza del proceso.
```{r}
dim(df) # La muestra es relativamente pequeña
```
Entonces se procede a graficar finalmente los datos diferenciados para mirar el resultado del modelo auto.arima de manera descriptiva

```{r}
plot(Diferencias.modelo, type = 'l') # Mejorar grafico
```
En principio, no tiene sentido aplicar un modelo ARIMA a unos datos que no se encuentran correlacionados y que, su diferencia parece cumplir los supuestos de ruido blanco (Con algunos problemas de varianza).

De esta manera se entiende el por qué el auto.arima otorga como resultado un modelo que tiene básicamente, una media y una desviación. 

Se opta por trabajar con una base de datos más grande. 
 

# Mismo problema, otros cerditos: Análisis nacional

Se tiene en el DANE una base de datos con el registro nacional de sacrificios cárnicos, para este caso; porcinos.


```{r include=FALSE}
cerditos_2_la_venganza <- read_excel("cerditos 2 la venganza.xls", 
    sheet = "Cuadro 3", skip = 9)
df2 =cerditos_2_la_venganza 


df2 = cerditos_2_la_venganza
df2 = df2 %>% clean_names()
```


```{r }
df2 %>% head(3)

```

La base de datos 2 (df2) corresponde a los análisis totales de cabezas porcinas sacrificadas. Con esto en mente, se tienen datos desde el 2008 hasta el 2022 con las respectivas variables. La escala de la variable es en cientos de miles. Se baja la escala para hacer más interpretable las gráficas.  

## Grafico sacrificios por Machos y Hembras


```{r}
df2$t_cabezas = df2$t_cabezas/100000
df2$machos = df2$machos/100000
df2$hembras = df2$hembras/100000
# --> construct separate plots for each series
obj1 <- xyplot(machos ~ fecha, df2, type = "l" , lwd=2)
obj2 <- xyplot(hembras ~ fecha, df2, type = "l", lwd=2)
 
# --> Make the plot with second y axis AND legend:
doubleYScale(obj1, obj2, text = c("sacrificios porcinos machos", "sacrificio porcinos hembras") , add.ylab2 = TRUE)
```
De manera análoga, se observa como el comportamiento en el tiempo de ambas series (Sacrificios de machos y de hembras) es similar.

```{r echo=FALSE, message=FALSE, warning=FALSE}

x = df2$fecha
y = df2$t_cabezas

# plot 

ggplot(df2, aes(x=fecha,y=t_cabezas))+
  geom_line(color = '#69b3a2', size = 1, alpha = 0.9)+
  theme_ipsum()+
  ggtitle('Total de sacrificios porcinos')

```
## Análisis descriptivos para la serie: 

Una vez graficada la serie, se proceden a realizar análisis descriptivos que permitan ver mejor el comportamiento general de la serie.


```{r}
df2$t_cabezas=df2$t_cabezas
vectores <- c(df2$t_cabezas)
dftimeserie <-ts(vectores, frequency = 12, start = c(2008,10))
descompuesta=decompose(dftimeserie)
plot(descompuesta)

```

Para la serie, se hace una descomposición aditiva de los datos. Estos revelan que:

 1) Hay tendencia creciente en la serie
 
 2) Hay estacionalidad en los datos (En principio, anual)
 
 3) Existe un dato atípico (en principio, se sospecha pandemia) en el gráfico de seasonal decompose, puesto que se ve un pico en el año '13'(Que representa el año 2008+13, es decir; 2021)
 
 El siguiente grafico permite ver de manera más clara la estacionalidad.


```{r}
ggseasonplot(dftimeserie,year.labels=TRUE,continuous=TRUE)
```
Con una escala de 100.000 cerdos sacrificados por cada unidad representada, se tiene que el mes de diciembre destaca por tener un mayor número de sacrificios en su respectivo año. Para este caso, se puede deducir una estacionalidad anual en dicho mes. Se debe ahondar en el fenómeno para entender por qué en diciembre se sacrifican más cerdos. Ahora, el sentido común apunta a que, en vísperas de época navideña el consumo de carnes aumenta.

```{r}
ts_seasonal((dftimeserie), type="box")

```
Al graficar los valores respectivos de la variable asociados a cada mes, se tiene que la media para el mes de diciembre es ligeramente mayor. Para apreciar mejor esta diferencia, se elimina la tendencia en los datos y se realiza el grafico.

```{r}
ts_seasonal(diff(dftimeserie), type="box")

```
Ahora, es más claro que el mes de diciembre presenta un comportamiento por encima de la media. Esto implica que, en dicho mes, se sacrifican más cerdos. De manera análoga, enero se encuentra por debajo de la media general del proceso. Estos dos meses han de ser tenidos en cuenta.

```{r}
ts_heatmap(diff(dftimeserie), color = "Reds")
```

En el mapa, se tiene de izquierda a derecha, el mismo mes en diferentes años. Ahora, note que, en diciembre, siempre se nota un mayor número de sacrificios. 

Verticalmente se tiene un año representado. Por año, nuevamente diciembre siempre destaca por ser el mes con mayor número de sacrificios.


```{r}

ggseasonplot(dftimeserie, polar = TRUE)
```

Se tiene a la derecha el conteo de años a partir del 2008, ahora; Cada año se encuentra graficado y espera ver estacionalidad en los datos. nuevamente, diciembre, destaca como mes con 'picos' 


## Modelamiento de la serie 

Para modelar apropiadamente la serie, se propone primero realizar un análisis descriptivo de la ACF y la PACF. Así, pues: 

*ACF:*


```{r}
acf(df2$t_cabezas)
```

Note que, debido a un decaimiento lento en la ACF, se ha de tomar en el modelo d>=1. Se procede entonces a tomar dicha diferencia y a graficar nuevamente la ACF.


```{r}
acf(df2$t_cabezas %>% diff %>% na.omit, lag.max = 50)
```

Al tomar diferencias para eliminar la tendencia, se nota que hay ruptura fuerte en los lags 1 y 12. Ahora, tenga presente que hay rupturas en otros lags, como 4 el. Esto en conjunto con la PACF permitirá entender cuál sería el posible modelo para utilizar. Puesto que podría ser muy subjetivo, podría entenderse como un corte en 4,8,11,12 (Destaca mucho más),13. Ahora, también podría interpretarse como un comportamiento senoidal con ruptura en 12. Dado este escenario, se procede a graficar la PACF.

Ahora, la estacionalidad se ve marcada en 12.
 

```{r}
pacf(df2$t_cabezas, lag.max = 35)
```
Al analizar la PACF, se percibe corte en los primeros lag (menos el 4) y en 8,11 y 12. Nuevamente, hay quien podría argumentar un comportamiento senoidal, por tanto se proponen modelos SARIMA(p,d,q)x(P,D,Q) para modelar la serie. Esto se realiza con la intención de entender en definitiva, al analizar la ACF y la PACF, el modelo resultante ha de ser un SARIMA, donde la frecuencia asociada al mismo ha de ser 12.


## Modelando la serie: SARIMA vs auto.arima

Se procede a realizar un ajuste de un modelo para la serie con la función de auto.arima; se desea comparar los resultados de dicha función con los análisis descriptivos hasta el momento.


```{r}
mod1 = auto.arima(df2$t_cabezas, stepwise = F, approximation = F, seasonal = T,)
checkresiduals(mod1)
```

```{r}
par(mfrow=c(1,2))
plot(arroots(mod1),main="Inverse AR roots")
plot(maroots(mod1),main="Inverse MA roots")
```


La ACF de los residuales muestra correlación en lag 12. Parece haber normalidad y a priori no se identifican datos atípicos. Ahora, también se aclara que la respectiva prueba de Ljung-Box rechaza no autocorrelación.
```{r}
shapiro.test(mod1$residuals)
```
La normalidad en los residuales no se cumple dado el test de shapiro-Wilk

```{r}

jarque.bera.test(mod1$residuals)
```
La normalidad en los residuales no se cumple dado el test de jarque-bera


```{r}
qqnorm(mod1$residuals)
qqline(mod1$residuals)
```

El grafico QQ-plot parece no tener desviaciones fuertes, a excepción del final del gráfico.

```{r}
summary(mod1)
```
Finalmente, auto.arima ajusta un modelo ARIMA (2,1,3); lo cual es contra intuitivo con el análisis estacional ya realizado. 

## Predicción auto.arima

Se proponen realizar predicciones con los modelos teniendo en cuenta toda la base de datos, sin hacer Back-testing. Esto en aras de tener una mejor idea de que están haciendo los modelos y, si es o no un buen ajuste a los datos. Para profundizar esto, más adelante se utilizarán técnicas de backtesting.


```{r}
# prediccion auto.arima

f_fit <- forecast(mod1)

autoplot(ts(df2$t_cabezas), series="Datos") + 
   autolayer(mod1$fitted, series="Modelo auto.arima ") +
   autolayer(f_fit, series="Prediction") +
   xlab("Year") + ylab("Total sacrificios (1/100.000)") + ggtitle("Total de sacrifios 2008-2022") + theme_bw()+theme(legend.title = element_blank(),legend.position = "bottom")

```

Note que, la función auto.arima ajusta un modelo ARIMA(2,1,3)
Ahora, se sabía con los análisis anteriores que la diferencia a tomar era 1 (d=1) y los valores de p y q podrían variar entre los mencionados. 
Ahora, también se sabía que la serie presentaba un comportamiento estacional. Sin embargo la función auto.arima NO muestra dicho comportamiento estacional en el modelamiento. 
Surge una pregunta, ¿Es este el mejor modelo, sin importar un análisis de estacionalidad? o, por otra parte, ¿la función carece de ajuste suficiente para detectar un buen modelo?.

Para esto, se seleccionan diferentes modelos propuestos con la intención de comparar sus valores y verificar cual tendría un mejor rendimiento.

NOTA: Se utiliza toda la base de datos por ahora, dado que se sospecha se realizarán intervenciones. Lo que en ultimas implica que las predicciones tienen sesgo. Mas adelante se divide entre datos de entrenamiento y datos de prueba para modelar y predecir.

*Algunos modelos propuestos:*

Se proponen algunos modelos de manera manual. Esto con la idea de ilustrar que, al variar los parámetros de los modelos; se pueden obtener diferentes AIC, BIC y en general, diferentes rendimientos. Luego, se calcula su AIC y BIC para contrastar cuales serán los mejores modelos.


```{r}
x = df2$t_cabezas
mod2 = arima(x, order = c(0,1,1))
mod3 = arima(x, order = c(1,1,1))
mod4 = arima(x, order = c(1,1,2))
mod5 = arima(x, order = c(2,1,1))
mod6 = arima(x, order = c(2,1,2))
mod7 = arima(x, order = c(3,1,1))
mod8 = arima(x, order = c(3,1,2))
mod9 = arima(x, order = c(1,1,3))
mod10 = arima(x, order = c(3,1,3))

cbind(AIC(mod1,mod2,mod3,mod4,mod5,mod6,
mod7,mod8,mod9,mod10),BIC(mod1,mod2,mod3,mod4,mod5,mod6,
mod7,mod8,mod9,mod10)[2])

```

Como era de esperarse, auto.arima muestra un mejor rendimiento a la hora de escoger modelo de manera manual pero se sospecha, NO es el mejor modelo para ajustar los datos. 


## Seleccionando mejor modelo

En un script aparte, se contrastan un total de 256 modelos (El archivo es de 8.8 mb) y para compilar el html, se presentan dificultades. De esta manera se empiezan a varias los parámetros p,d,q, P,D,Q con estacionalidad en 12; para escoger de todos los posibles modelos resultantes, el mejor.


```{r}
load('256modelos.Rdata')
```

Este archivo contiene el 'summary' de 256 modelos. De aquí, se obtiene después de un procesamiento; los datos del modelo optimo según ciertos criterios de selección.

Los códigos para ver cómo se calcula los modelos se encuentran *aquí*

*Modelo optimo según AIC*

El modelo resultante con mejor rendimiento AIC y BIC no es necesariamente el modelo con un menor valor (Seria tan fácil como buscar el mínimo de toda la lista) pero, esto no es factible dado que se desea seguir el principio de parsimonia. Esto se menciona dado que el SARIMA optimo era de ordenes (3,1,4)x(4,1,1). Ahora, la diferencia en el ajuste respecto al seleccionado no era mayor.

Así pues, el modelo resultante es un SARIMA (1,0,1)x(0,1,0); que presenta un buen rendimiento.


```{r}
prueba = Arima(dftimeserie, order = c(1,0,1),
               seasonal = list(order = c(0,1,0),period =12))
checkresiduals(prueba)
```
```{r}
par(mfrow=c(1,2))
plot(arroots(prueba),main="Inverse AR roots")
plot(maroots(prueba),main="Inverse MA roots")
```
Ahora, dicho modelo posee problemas en sus supuestos. Tiene correlación en sus residuales y problemas de normalidad.
```{r}
shapiro.test(prueba$residuals)
```
No normalidad según Shapiro Wilk

```{r}
jarque.bera.test(prueba$residuals)
```

No normalidad, según Jarque-Bera
```{r}
qqnorm(prueba$residuals)
qqline(prueba$residuals)
```
Desviaciones fuertes en el QQ-plot.


```{r}
summary(prueba)
```

Al comparar diferentes medidas entre sí, el modelo no necesariamente es el que tiene mejor RMSE, MAE, AIC o BIC. Sin embargo; la diferencia entre estos no era muy significativa y los ajustes son relativamente buenos. 

Finalmente, se procede a ajustar una predicción con toda la base de datos dado este modelo. 

*Predicción modelo seleccionado*


```{r}
f_fit <- forecast(prueba)
 autoplot(dftimeserie, series="Datos") + 
   autolayer(prueba$fitted, series="SARIMA(1,0,1)(0,1,0)[12] ") +
   autolayer(f_fit, series="Prediction") +
   xlab("Year") + ylab("Total sacrificios (1/100.000)") + ggtitle("Total de sacrifios 2008-2022") + theme_bw()+theme(legend.title = element_blank(),legend.position = "bottom")
```

Note que la predicción del modelo de auto.arima es más pobre. Esto dado que; hace falta realizar un ajuste de estacionalidad. Ahora, este modelo como es de esperarse es más preciso cuando la predicción es más cercana en el tiempo. 


*Holt-Winters 1.0*

Análogamente, se procede a realizar un ajuste con un modelo Holt-Winters para predecir. Dicho modelo es calculado con el siguiente código y, allí mismo se ajustan las predicciones.

Se modifican algunos parámetros del modelo de Holt-Winters. Después de realizar algunas pruebas se escoge el siguiente modelo:


```{r}
# Custom HoltWinters fitting
HW2 <- hw(dftimeserie, alpha=0.2, beta=0.1, gamma=0.1)
```

Y las respectivas predicciones asociadas a dicho modelo son:

```{r}
HW2.pred <- forecast(HW2)
#Visually evaluate the prediction
autoplot(dftimeserie, series="Datos") + 
   autolayer(HW2$fitted, series="Modelo auto.arima ") +
   autolayer(HW2.pred, series="Prediction") +
   xlab("Year") + ylab("Total sacrificios (1/100.000)") + ggtitle("Total de sacrifios 2008-2022") + theme_bw()+theme(legend.title = element_blank(),legend.position = "bottom")
```

Note que existe una predicción parecida a los modelos anteriores pero con IC más amplios, por tanto; es menos precisa. 

*Modelo de Holt-Winters 2.0*

Se propone otro modelo con modelo con HW buscando los parámetros óptimos de manera automática.

```{r}
# Custom HoltWinters fitting
HW2ensayo <- hw(dftimeserie,  optim.start = c(alpha = 0, beta = 0, gamma = 0))
```

```{r}
HW2ensayo.pred <- forecast(HW2ensayo)
#Visually evaluate the prediction
autoplot(dftimeserie, series="Datos") + 
   autolayer(HW2ensayo$fitted, series="Modelo auto.arima ") +
   autolayer(HW2ensayo.pred, series="Prediction") +
   xlab("Year") + ylab("Total sacrificios (1/100.000)") + ggtitle("Total de sacrifios 2008-2022") + theme_bw()+theme(legend.title = element_blank(),legend.position = "bottom")
```
Note que ahora, el modelo tiene una predicción más coherente y un IC más angosto. Falta preguntarse, ¿Cuál es el mejor modelo? Pero, para responder a esta pregunta se hace la siguiente comparación.

## tabla de acurracy de modelos propuestos

Tabla resumen con los modelos propuestos.


```{r}
model_comp <- data.frame(accuracy(mod1)[1:6],
                         accuracy(prueba)[1:6],
                        accuracy(HW2)[1:6],
                        accuracy(HW2ensayo)[1:6],
                         row.names = c("ME", "RMSE",
                                       "MAE", "MPE",
                                       "MAPE","MASE"))
colnames(model_comp) <- c('auto.arima','Ajustado','HW1','HW2')

model_comp %>% kableExtra::kable() 
```

En general, los modelos que tienen mejor rendimiento son los HW 1 y 2. Se ha de escoger uno de ellos para modelar. Sin embargo, se deben realizar pruebas de backtesing para comparar. No necesariamente la técnica es aplicable a todos los modelos, pero, ¿por qué no probar?

## Back-Testing

Para modelar correctamente, se utiliza back-testing; aquí se divide en datos de entrenamiento y prueba.
Se trabajará con el 80% de los datos. Así pues:


```{r}

df3 = df2[,1:2] # serie con la que se trabajará
n = df3$t_cabezas %>% length() # 168 observaciones
split = (n*0.8) %>% round() # se toman 134 datos
indice = df3[split,] # Fecha dividida hasta el 2019

# Division datos de entrenamiento
train = df3[1:split,] #134 datos

# Division datos de prueba
test = df3[(split+1):nrow(df3),] # 34 datos


```

## Grafica datos entrenamiento y prueba:

```{r}
serie.original = df2$t_cabezas
#prediccions = as.data.frame(prediccions)
s1 = train$t_cabezas # termina en septiembre del 2022 DATOS DE ENTRENAMIENTO
s2 = test$t_cabezas #

a1 = ts(s1, frequency = 12, start = c(2008,10))# ENTRENAMIENTO
a2 = ts(s2, frequency = 12, start = end(a1)) # PRUEBA

#Visually evaluate the prediction
autoplot(a1, series="Datos entrenamiento") + 
   autolayer(a2, series="Datos de prueba") +
   #autolayer(HW2.pred, series="Prediction") +
   xlab("Year") + ylab("Total sacrificios (1/100.000)") + ggtitle("Total de sacrifios 2008-2022") + theme_bw()+theme(legend.title = element_blank(),legend.position = "bottom")
```

Con la base de datos dividida, se procede a analizar el ajuste de los modelos vía Back-Testing.

## Modelos con Back-Testing

Todos los modelos utilizados en la serie anterior se utilizan para predecir ahora; evaluarlos vía back-Testing.


```{r echo=FALSE}
mod1 = auto.arima(s1, stepwise = F, approximation = F, seasonal = T,) # ARIMA(0,1,5)
mod2 = Arima(s1, order = c(1,0,1),
               seasonal = list(order = c(0,1,0),period =12)) # SARIMA (1,0,1)x(0,1,0)
mod3 <- hw(ts(train$t_cabezas, frequency = 12, start = c(2008,10)), alpha=0.2, beta=0.1, gamma=0.1,h = 34)
mod4 <- hw(ts(train$t_cabezas, frequency = 12, start = c(2008,10)),  optim.start = c(alpha = 0, beta = 0, gamma = 0), h=34)
```
Para calcular el modelo con mejor rendimiento, se procede a calcular el MSE asociado a cada modelo. De esta manera:

```{r}
# PREGUNTAR SI ES ASI
y = test$t_cabezas # valor de y_test; reales

a1 = forecast(mod1,h = 34) # prediccion modelo 1
y_hat1 = a1$mean

a2 = forecast(mod2,h=34)  # prediccion modelo 2
y_hat2 = a2$mean

a3 = mod3  # prediccion modelo 3 
y_hat3 = a3$mean

a4 <- mod4 # prediccion modelo 4
y_hat4 <- a4$mean
```

```{r}
mse1 = mean((y-y_hat1))^2
mse2 = mean((y-y_hat2))^2
mse3 = mean((y-y_hat3))^2
mse4 = mean((y-y_hat4))^2
```


```{r echo=FALSE}
tabla = cbind(c(mse1,mse2,mse3,mse4))
colnames(tabla) = c("MSE")
rownames(tabla) = c("Modelo 1","Modelo 2","Modelo 3","Modelo 4")
tabla %>% kable
```

De esta manera, entonces; el modelo optimo será el que tenga un menor MSE. El modelo con mejor rendimiento es el modelo 4, que respectivamente corresponde al modelo con menor MSE. 

Se adjuntan las siguientes métricas para la selección ideal del modelo.

```{r}
model_comp <- data.frame(accuracy(mod1)[1:6],
                         accuracy(mod2)[1:6],
                        accuracy(mod3)[1:6],
                        accuracy(mod4)[1:6],
                         row.names = c("ME", "RMSE",
                                       "MAE", "MPE",
                                       "MAPE","MASE"))
colnames(model_comp) <- c('Modelo 1','Modelo 2','Modelo 3','Modelo 4')

model_comp %>% kableExtra::kable() 
```
Según la anterior tabla, el modelo con mejor rendimiento es el modelo 4. Se muestra a continuación.
```{r}
mod4$model
```

Este es un modelo Holt-Winters con los parámetros anteriores. Ahora, como este modelo no tiene supuestos de normalidad en los residuales...
Pues bastaría lanzar una predicción.


```{r}
# prediccion HW

f_fit <- y_hat4

autoplot(dftimeserie, series="Datos") + 
   autolayer(mod4$fitted, series="Modelo HW fitted ") +
   autolayer(f_fit, series="Prediction") +
   #autolayer()+
   xlab("Year") + ylab("Total sacrificios (1/100.000)") + ggtitle("Total de sacrifios 2008-2022") + theme_bw()+theme(legend.title = element_blank(),legend.position = "bottom")

```

En el grafico anterior, se tiene los datos en rojo, los ajustados por el modelo HW en verde u finalmente la predicción para los datos de prueba. No se grafica el IC dado que puede ser caótico para visualizar. Ahora, dicho grafico seria:
```{r}
f_fit <- forecast(mod4,h=34)
autoplot(dftimeserie, series="Datos") + 
   #autolayer(mod4$fitted, series="Modelo HW fitted ") +
   autolayer(f_fit, series="Prediction") +
   #autolayer()+
   xlab("Year") + ylab("Total sacrificios (1/100.000)") + ggtitle("Total de sacrifios 2008-2022") + theme_bw()+theme(legend.title = element_blank(),legend.position = "bottom")

```

Ahora, acá se tienen los datos reales en rojo y solo la predicción. Note como el modelo tiene peor rendimiento que cuando se ajusta con la totalidad de la base de datos. Sin embargo, el ajuste de la serie predicha por el modelo no es necesariamente malo. Ahora, recuerde que entre más predicciones en el tiempo se hagan, más imprecisa es la predicción. 



## Análisis de outliers

Observe de nuevo la serie original. Con esta serie se busca entonces entender si existe un comportamiento de datos atípicos. Ahora, note que:


```{r echo=FALSE}
plot(dftimeserie)
```
De manera descriptiva se observa que para el año 2020 se tiene una caída más pronunciada. Se desea observar si para dicho dato existe evidencia de ser un outlier.

La función tso del paquete tsoutliers permite analizar los datos atípicos de una serie de tiempo. 

*Modelo de Outliers*


```{r}
mod_outliers <- tso(dftimeserie, delta=0.7)

mod_outliers 
```

Por defecto, el modelo de los outliers deja fijado un delta de 0.7; se propone variar el delta para empezar a detectar cuales son los outliers detectados al variar delta. Dado el coste computacional, se definen deltas menores a 0.9 con saltos de 0.1

Note que el modelo seleccionado vía 256 modelos, es el mismo que selecciona automáticamente la función tso.


```{r}
# Modelos aplicados de esta forma por menos coste computacional
mod_outliers0 <- tso(dftimeserie, delta=0)
mod_outliers1<- tso(dftimeserie, delta=0.1)
mod_outliers2 <- tso(dftimeserie, delta=0.2)
mod_outliers3<- tso(dftimeserie, delta=0.3)
mod_outliers4 <- tso(dftimeserie, delta=0.4)
mod_outliers5 <- tso(dftimeserie, delta=0.5)
mod_outliers6 <- tso(dftimeserie, delta=0.6)
mod_outliers7 <- tso(dftimeserie, delta=0.7)
mod_outliers8 <- tso(dftimeserie, delta=0.8)
mod_outliers9 <- tso(dftimeserie, delta=0.9)
mod_outliers10 <- tso(dftimeserie, delta=1)

```

```{r echo=FALSE}
mod_outliers0$outliers %>% kable(label = 'Delta 0')
```

```{r echo=FALSE}
mod_outliers1$outliers %>% kable(label = 'Delta 1')
```

```{r echo=FALSE}
mod_outliers2$outliers %>% kable(label = 'Delta 2')
```
```{r echo=FALSE}
mod_outliers3$outliers %>% kable(label = 'Delta 3')
```
```{r echo=FALSE}
mod_outliers4$outliers %>% kable(label = 'Delta 4')
```
```{r echo=FALSE}
mod_outliers5$outliers %>% kable(label = 'Delta 5')
```
```{r echo=FALSE}
mod_outliers6$outliers %>% kable(label = 'Delta 6')
```
```{r echo=FALSE}
mod_outliers7$outliers %>% kable(label = 'Delta 7')
```
```{r echo=FALSE}
mod_outliers8$outliers %>% kable(label = 'Delta 8')
```
```{r echo=FALSE}
mod_outliers9$outliers %>% kable(label = 'Delta 9')
```
```{r echo=FALSE}
mod_outliers10$outliers %>% kable(label = 'Delta 10')
```
Note que, de manera general, los modelos hasta un delta de 0.6 identifican a la observación 139 como un dato atípico. Este dato coincide con Marzo del 2020, en cual se declara pandemia. Por este motivo, se podría esperar que la observación 139 sea un dato atípico AO, es decir; afectó momentáneamente la serie de tiempo y luego esta se normalizó. Por tal motivo se concluye que se ha de modelar con una función pulso. 

Ahora, al variar el parámetro, aparecen otros outliers e incluso el 139 es detectado como otro tipo de outlier, sin embargo; todos los otros no tuvieron causas asignables para ser dictaminados como datos atípicos por variables exógenas; así que se opta por aplicarle una función pulso. 

## Intervención

Se procede a dividir la serie antes de la intervención. Esto se selecciona basado en una idea muy simple; posiblemente la pandemia pudo afectar el número de sacrificios mensuales. En la serie, es el dato 139 el cual corresponde a marzo del 2020 (donde se evidencia la caída).


```{r echo=FALSE}
ensayointervencio <- window(dftimeserie, start=time(dftimeserie)[1],
                end = time(dftimeserie)[138])
paco = ensayointervencio %>% auto.arima(stepwise = F,approximation = F) 
paco %>% summary()
```

Finalmente, se tiene que los órdenes del modelo con auto.arima; así pues, se tiene un ARIMA(3,0,0)(0,1,2)[12]; para un modelo ajustado antes de la intervención. 

Entonces, este es el modelo con la intervención a la observación 139.

## *Función pulso:*


```{r}
modelo1superintervencion <- arimax(dftimeserie, order=c(3, 0, 0),seasonal = list(order = c(0, 1, 2)),
xtransf=data.frame( creemosquepandemia=1 *(seq_along(dftimeserie) == 139)),
transfer=list(c(1, 0)))
modelo1superintervencion %>% coeftest()
```

Dada esta tabla, se busca entender cuál de los coeficientes son o no significativos. 

Entonces, como el AR1 NO es significativo; se concluye que la función a utilizar es una función pulso. Dicho de otra manera (Mas bonita):

El δ1 estimado (0.034201x100.000 =3420.1 ) no es significativo con un nivel de significancia del 5 %. En cambio, el ω1 estimado (-0.692464x100000=-69246.4 ) sí es significativo; lo que implica que la caída dada por pandemia es de cerca de 69246 cabezas de marranos.

En pocas palabras, la pandemia afectó en promedio la producción de cabezas porcinas en casi 70 mil unidades menos de lo que se producía normalmente.


```{r}
modelo1superintervencion2 <- arimax(dftimeserie, order=c(3, 0, 0),seasonal = list(order = c(0, 1, 2)),
xtransf=data.frame( creemosquepandemia=1 *(seq_along(dftimeserie) == 139)),

transfer=list(c(0, 0)))
modelo1superintervencion2 %>% coeftest()
```

Finalmente, al analizar los datos realizando la intervención, se concluye que el modelo es significativo en todos sus parámetros entonces; se procede a predecir con dicho modelo intervenido.

## Predicción con modelo intervenido. 

Para realizar las predicciones con el modelo intervenido, se ha de revisar los supuestos del modelo. Entonces:

```{r}
modelo1superintervencion2 %>% checkresiduals()
```

Al analizar de manera descriptiva, el modelo parece seguir una distribución normal, la ACF detecta autocorrelación y, parece que los errores tienen problemas de autocorrelación.

Respecto a outliers, se detectan algunos puntos marcados, pero no tienen asociados causas asignables.

Varianza constante (en principio); Por otra parte, se observa que la prueba de correlación de los residuales de Ljung-Box determina correlación en los residuales. 

Aun así, dada las condiciones del modelo se decide *NO* intervenir nuevamente, puesto que se podría sobre ajustar. 

*Normalidad residuales: *


```{r echo=FALSE}
modelo1superintervencion2$residuals %>% shapiro.test()
```
Note que, aunque así lo parezca; los errores según la prueba de Shapiro-Wilk no son normales. Se procede a analizar el QQ-plot.
```{r echo=FALSE}
qqnorm(modelo1superintervencion2$residuals)
qqline(modelo1superintervencion2$residuals)
```

Note que los residuales tienen en general un buen ajuste a la recta de normalidad. El QQ-plot tiene algunos datos atípicos. 

## Predicciones con modelo intervenido

Finalmente, se procede a realizar las predicciones con el modelo intervenido.

A continuación se muestra el modelo intervenido.

```{r echo=FALSE}
modelo1superintervencion2
```

```{r}

reg1 <- stats::filter(1 * (seq.int(length(dftimeserie) + 12)== 139),

filter =0, method = "rec",
sides = 1)
xreg <- cbind(I1=stats::filter(1*(seq_along(dftimeserie) == 139),method = "rec",sides = 1,filter = 0))

modelo_intervenido <-arima(dftimeserie, order = c(3,0, 0),
seasonal = list(order = c(0,1,2),
period = 12), xreg = xreg)
```

```{r}
modelo_intervenido %>% coeftest()
```
Note que para cada parametro del modelo, se tiene que son significativos.

```{r message=FALSE, warning=FALSE}
df2$t_cabezas=df2$t_cabezas
vectores <- c(df2$t_cabezas)
dftimeserie <-ts(vectores, frequency = 12, start = c(2008,10))
reg1 <- ts(reg1, start = start(dftimeserie),
frequency = frequency(dftimeserie)) # hasta aca se tiene 0 y 1 en la intervencion
reg1_new <- window(reg1, start = c(2022,09), end = c(2023,08))

inter.pred = predict(modelo_intervenido, newxreg=reg1_new, n.ahead=12)
inter.pred # Estas son las predicciones
```

```{r}
prediccions = inter.pred$pred # serie de tiempo de la prediccion
se = inter.pred$se # para crear los IC
```

```{r}
MSE = mean((df2$t_cabezas- fitted.values(modelo_intervenido)))^2
MSE
```
El MSE de este modelo es del orden de 0.000007387; Hasta el momento, ningún modelo ha ajustado un MSE tan pequeño.
De esta manera, este modelo con intervenciones; parece el modelo más confiable para realizar predicciones.

# Grafica de la predicción


```{r}
serie.original = df2$t_cabezas
prediccions = as.data.frame(prediccions)
s1 = df2$t_cabezas # termina en septiembre del 2022
s2 = prediccions #

a1 = ts(s1, frequency = 12, start = c(2008,10))
a2 = ts(s2, frequency = 12, start = c(2022,09))

#Visually evaluate the prediction
autoplot(a1, series="Datos") + 
   autolayer(a2, series="Predicciones") +
   #autolayer(HW2.pred, series="Prediction") +
   xlab("Year") + ylab("Total sacrificios (1/100.000)") + ggtitle("Total de sacrifios 2008-2022") + theme_bw()+theme(legend.title = element_blank(),legend.position = "bottom")
```

Finalmente, se tienen las predicciones con su respectivo IC.


