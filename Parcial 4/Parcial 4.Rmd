---
title: "Series de tiempo - Parcial 4"
author: "Felipe Lopera & Jhonatan Smith"
date: "2022-10-09"
output: rmdformats::readthedown
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, warning=FALSE, include=FALSE}
require(dplyr)
require(lmtest)
require(tseries)
require(TSA)
require(astsa)
require(tsoutliers)
require(kableExtra)
require(tidyverse)
require(ggplot2)
require(hrbrthemes)
require(tsoutliers)
require(TSstudio)
require(forecast)
require(latticeExtra)
require(datetime)
library(lubridate)
require(forecast)
library(readxl)
require(forecast)
require(readr)
require(janitor)
```


# Base de datos nacimientos hospital 

```{r include=FALSE}

# fn para calcular las raices unitarias y graficas bien chimbita
arroots <- function(object)
{
  if(!("Arima" %in% class(object)) &
     !("ar" %in% class(object)))
    stop("object must be of class Arima or ar")
  if("Arima" %in% class(object))
    parvec <- object$model$phi
  else
    parvec <- object$ar
  if(length(parvec) > 0)
  {
    last.nonzero <- max(which(abs(parvec) > 1e-08))
    if (last.nonzero > 0)
      return(structure(list(
          roots=polyroot(c(1,-parvec[1:last.nonzero])),
          type="AR"),
        class='armaroots'))
  }
  return(structure(list(roots=numeric(0), type="AR"),
    class='armaroots'))
}

# Compute MA roots
maroots <- function(object)
{
  if(!("Arima" %in% class(object)))
    stop("object must be of class Arima")
  parvec <- object$model$theta
  if(length(parvec) > 0)
  {
    last.nonzero <- max(which(abs(parvec) > 1e-08))
    if (last.nonzero > 0)
      return(structure(list(
          roots=polyroot(c(1,parvec[1:last.nonzero])),
          type="MA"),
        class='armaroots'))
  }
  return(structure(list(roots=numeric(0), type="MA"),
    class='armaroots'))
}

plot.armaroots <- function(x, xlab="Real", ylab="Imaginary",
    main=paste("Inverse roots of", x$type,
          "characteristic polynomial"),
    ...)
{
  oldpar <- par(pty='s')
  on.exit(par(oldpar))
  plot(c(-1,1), c(-1,1), xlab=xlab, ylab=ylab,
       type="n", bty="n", xaxt="n", yaxt="n", main=main, ...)
  axis(1, at=c(-1,0,1), line=0.5, tck=-0.025)
  axis(2, at=c(-1,0,1), label=c("-i","0","i"),
    line=0.5, tck=-0.025)
  circx <- seq(-1,1,l=501)
  circy <- sqrt(1-circx^2)
  lines(c(circx,circx), c(circy,-circy), col='gray')
  lines(c(-2,2), c(0,0), col='gray')
  lines(c(0,0), c(-2,2), col='gray')
  if(length(x$roots) > 0)
  {
    inside <- abs(x$roots) > 1
    points(1/x$roots[inside], pch=19, col='black')
    if(sum(!inside) > 0)
      points(1/x$roots[!inside], pch=19, col='red')
  }
}
```

Inicialmente se desea trabajar con un indice. Proporcion de niñas nacidas vs niños nacidos ; es decir:

Hembra/ macho; queremos ver si es igual, menor y si esto tiene una evolucion en el tiempo.

```{r warning=FALSE}
datos <- read.csv("Nacidos_Vivos_en_Hospital_Manuel_Uribe_Angel.csv")
datos$FECHA.NACIMIENTO <- gsub(" \\d+:\\d+:\\d+ .*", "", datos$FECHA.NACIMIENTO)
datos$FECHA.NACIMIENTO <- as.Date(datos$FECHA.NACIMIENTO, format = "%m/%d/%Y")
datos <- datos %>%  mutate(Anio = year(FECHA.NACIMIENTO), semana = week(FECHA.NACIMIENTO)) %>% 
  group_by(Anio, semana) %>% 
  summarise(ratio = sum(SEXO != "MASCULINO")/sum(SEXO == "MASCULINO"))
lambda <- forecast::BoxCox.lambda(datos$ratio)
datos$ratio <- forecast::BoxCox(datos$ratio, lambda)

pacf(datos$ratio)
```

Empezamos mal...

```{r}
acf(datos$ratio)
```

Y terminamos pior. 


```{r}
x = datos$ratio
plot(x, type = "l")
```


Ombe pues bonita si se ve peeero... Y entonces?

```{r}
mod <- forecast::auto.arima(datos$ratio)
summary(mod)
```

Como dijo aquella figura de la tv mexicana; 'Lo sospeché desde un principio'

```{r warning=FALSE}
fit <- mod
par(mfrow=c(1,2))
plot(arroots(fit),main="Inverse AR roots")
plot(maroots(fit),main="Inverse MA roots")
```

Basicamente vale monda este modelo. No el modelo, el problema

¿Que pasó con las raíces? # Maso, oh tu que todo lo sabes. Iluminad a este pobre mortal, pues la luz de la esperanza se escapa ante cada linea de codigo que escribe.

Hipotesis: La naturaleza del problema no responde a un analisis de series temporales. La proporcion de nacimientos de niños vs niñas no varia en el tiempo; no es un dato temporal. 

Nota para smith del futuro: Basicamente, piense en la teoria antes de perder toda la tarde haciendo estas pendejadas buscando soluciones rebuscadas. KISS
# Base de datos cerditos (Yopal)

## Marco teorico: ¿Por qué los cerditos?

![Un lindo cerdito](C:/Users\jhsga\OneDrive\Escritorio\ODINSA\Parcial-4-series-de-tiempo\Parcial 4\tierno.jpg)

Tenga presente que el analisis del consumo carnico para una poblacion es importante pueto que a las entidades gubernamentales le permite controlar y entender dicho comportamiento para identificar y preveer posibles problemas de salud publica o en su defecto, generar politicas para controlar la economia 
del consumo. Se entiende pues, que un analisis para con el consumo es de vital importancia para los analisis demograficos de una poblacion. 

Tambien, tener un control total sobre la cantidad de cerdos sacrificados, ayuda a las entidades sanitarias a mantener un estandar en dicha produccion. Si esto no es regulado, se pueden propagar enfermedadas por la mala praxis en la industria. 

En el presente analisis, se desea predecir el numero total de cabezas porcinas sacrificadas. 

# PERO AUN MAS IMPORTANTE:

![Una chuleta](C:/Users\jhsga\OneDrive\Escritorio\ODINSA\Parcial-4-series-de-tiempo\Parcial 4\chuleta.jpg)
El factor economico. Y sabrozo del asunto. 

## Procesamiento de la base de datos

El primer paso es la lectura de los datos. Dado que los nombres
de la serie se encuentran inapropiados para trabajar con ellos, se corrigen los mismos despues de leer la base de datos.

```{r message=FALSE, warning=FALSE}

df = read_delim("cerdos.csv", delim = ";", escape_double = FALSE, trim_ws = TRUE)
df = clean_names(df)
df %>% names()
```

La variable año se convierte en 'ano'. Nos gusta ese nombre entonces, asi se queda. La base de datos tiene las siguientes variables.

Descripcion de las variables en el dataframe:

 *Ano:* Año en el que se toma el registro
 
 *sacrificios_porcinos_machos:* El nombre lo indica, cantidad de sacrificios porcinos machos
 
 *sacrificio_porcinos_hembras:* Cantidad de sacrificios porcinos de hembras
 
 *mes:* Mes en el cual se realizó el sacrificio
 
 *Longitus y latitud:*Ubicacion espacial del lugar de sacrificio 
 
 *sacrificio_totales:* Sacrificios totales porcinos
 
Respecto a la variable 'mes' se encuentra en formato caracter y, representa los meses en español.

```{r}
df$mes %>% unique() # Se verifica que no estén repetidos valores
```
Se procede entonces a crear la variable 'date' que representará la fecha asociada a cada dato.

```{r}
df$mes =as.factor(df$mes)
df$mes %>% levels# Se convierte en factor, cambia el orden
month_id = c(4,8,12,1,2,7,6,3,5,11,10,9)
levels(df$mes) = month_id
df$mes = df$mes %>% as.character()
```
Cuando se aplica la funcion as.factor, el orden de los mismos cambia. Entonces simplemente, se cambiará los niveles de la variable como factor a un valor numerico, siendo 1 enero, 2 febrero y asi sucesivamente. Luego, se transforma en string (Caracter) para obtener finalmente el mes en numero.

Para adquirir correctamente el formato en date, se ha de tener un dia cualquiera agregado. Se escoge el dia 13. 

```{r}
df$dia = replicate(length(df$ano), '13')
df$ano = df$ano %>% as.character()

df$date = paste(df$dia,df$mes,df$ano,sep = '-')
df$date = as.Date(df$date, format = '%d-%m-%Y')
# Con esto, se tiene la base de datos lista para trabajar

df = df[order(df$date),] # ordenando por fecha mas vieja
```

## Grafico de la serie

Se procede a graficas las series por Macho, Hembra y Total de sacrificios en orden cronologico.

## Total por Macho y Hembra

```{r}

# --> construct separate plots for each series
obj1 <- xyplot(sacrificios_porcinos_machos ~ date, df, type = "l" , lwd=2)
obj2 <- xyplot(sacrificio_porcinos_hembras ~ date, df, type = "l", lwd=2)
 
# --> Make the plot with second y axis AND legend:
doubleYScale(obj1, obj2, text = c("sacrificios_porcinos_machos", "sacrificio_porcinos_hembras") , add.ylab2 = TRUE)
```

En principio, no parece haber una diferencia significativa de una serie respecto a la otra. Se nota que una de las series está ligeramente por encima de la otra pero; los patrones de ambas son muy similares.

## Total de sacrificios porcinos

```{r echo=FALSE, message=FALSE, warning=FALSE}

x = df$date
y = df$sacrificio_totales

# plot 

ggplot(df, aes(x=date,y=sacrificio_totales))+
  geom_line(color = '#69b3a2', size = 1.5, alpha = 0.9)+
  theme_ipsum()+
  ggtitle('Total de sacrificios porcinos')

```

La grafica del total de sacrificios porcinos sigue un comportamiento similar a cuando se categoriza por sexo. Ahora, se decide trabajar con la serie del total por simplicidad. 

Ahora, normalmente los cerdos machos poseen un mayor peso dada su contextura, por esto es que; es normal entender que la relacion de cantidad totales sacrificadas sea ligeramente mayor por macho que por hembra. Para los intereses del analisis, se hará con el total de cerdos. 

## Primer modelo con auto.arima

Se utiliza esta primera funcion como un primer acercamiento para entender que se identifica de manera automatica. 

```{r}
mod1 = auto.arima(df$sacrificio_totales)
mod1 %>% summary()

```

Para este caso puntual, el modelo que sugiere el auto.arima es un ARIMA(0,1,0). ¿Tiene esto sentido?

## Analisis de la ACF y PACF

```{r}
acf(df$sacrificio_totales) 
```

Note que la ACF muestra un decaimiento lento. Por tal motivo, se han de tomar diferencias (Esto indica, d>=1) en el modelo. Se grafica la acf diferenciada

```{r}
Diferencias.modelo = na.omit(diff(df$sacrificio_totales))
acf(Diferencias.modelo)
```
Note que al tomar una diferencia, parece haber un corte en el lag 15. Aun asi, se podria pensar que es muy poco significativo; dado que una autocorrelacion de orden 15 implicaria que los datos se relacionan. Igualmente que un lag de 8. No se tiene seguridad en la significancia de los lags asociados a la ACF

```{r}
pacf(df$sacrificio_totales)
```

Note que la PACF muestra que no hay autocorrelacion parcial en los datos asociados a el sacrificio total. ¿Por qué? Se podria suponer que los datos a priori no parecen responder a una variable temporal. Esto es pues, una sospecha infundada ya sea por el tamaño de la muestra o por la naturaleza del proceso.

```{r}
dim(df) # La muestra es relativamente pequeña
```
Entonces se procede a graficar finalemente los datos diferenciados para mirar el resultado del modelo auto.arima de manera descriptiva

```{r}
plot(Diferencias.modelo, type = 'l') # Mejorar grafico
```
En principio, no tiene sentido aplicar un modelo ARIMA a unos datos que no se encuentran correlacionados y que, su diferencia parece cumplir los supuestos de ruido blanco (Con algunos problemas de varianza).

De esta manera se entiende el por qué el auto.arima otorga como resultado un modelo que tiene basicamente, una media y una desviacion. 

Se opta por trabajar con una base de datos mas grande. 
 

# Mismo problema, otros cerditos: Analisis nacional

Se tiene en el dane una base de datos con el registro nacional de sacrificios carnicos, para este caso; porcinos. 

```{r include=FALSE}
cerditos_2_la_venganza <- read_excel("cerditos 2 la venganza.xls", 
    sheet = "Cuadro 3", skip = 9)
df2 =cerditos_2_la_venganza 


df2 = cerditos_2_la_venganza
df2 = df2 %>% clean_names()
```


```{r }
df2 %>% head(3)

```

La base de datos 2 (df2) corresponde a los analisis totales de cabezas porcinas sascrificadas. Con esto en mente, se tienen datos desde el 2008 hasta el 2022 con las respectivas variables. La escala de la variable es en cientos de miles. Se baja la escala para hacer mas interpretable las graficas.  

## Grafico sacrificios por Machos y Hembras

```{r}
df2$t_cabezas = df2$t_cabezas/100000
df2$machos = df2$machos/100000
df2$hembras = df2$hembras/100000
# --> construct separate plots for each series
obj1 <- xyplot(machos ~ fecha, df2, type = "l" , lwd=2)
obj2 <- xyplot(hembras ~ fecha, df2, type = "l", lwd=2)
 
# --> Make the plot with second y axis AND legend:
doubleYScale(obj1, obj2, text = c("sacrificios porcinos machos", "sacrificio porcinos hembras") , add.ylab2 = TRUE)
```
De manera analoga, se observa como el comportamiento en el tiempo de ambas series (Sacrificios de machos y de hembras) es similar. 

```{r echo=FALSE, message=FALSE, warning=FALSE}

x = df2$fecha
y = df2$t_cabezas

# plot 

ggplot(df2, aes(x=fecha,y=t_cabezas))+
  geom_line(color = '#69b3a2', size = 1, alpha = 0.9)+
  theme_ipsum()+
  ggtitle('Total de sacrificios porcinos')

```
## Analisis descriptivos para la serie: 

Una vez graficada la serie, se proceden a realizar analisis descriptivos que permitan ver mejor el compportamiento general de la serie.

```{r}
df2$t_cabezas=df2$t_cabezas
vectores <- c(df2$t_cabezas)
dftimeserie <-ts(vectores, frequency = 12, start = c(2008,10))
descompuesta=decompose(dftimeserie)
plot(descompuesta)

```

Para la serie, se hace una descomposicion aditiva de los datos. Estos revelan que:

 1) Hay tendencia creciente en la serie
 
 2) Hay estacionalidad en los datos (En principio, anual)
 
 3) Existe un dato atipico (en principio, se sospecha pandemia) en el grafico de seasonal decompose, puesto que se ve un pico en el año '13'(Que representa el año 2008+13, es decir; 2021)
 
 El siguiente grafico permite ver de manera mas clara la estacionalidad. 

```{r}
ggseasonplot(dftimeserie,year.labels=TRUE,continuous=TRUE)
```
Con una escala de 100.000 cerdos sacrificados por cada unidad representada, se tiene que el mes de diciembre destaca por tener un mayor numero de sacrificios en su respectivo año. Para este caso, se puede deducir una estacionalidad anual en dicho mes. Se debe ahondar en el fenomeno para entender por qué en diciembre se sacrifican más cerdos. Ahora, el sentido comun apunta a que, en visperas de epoca navideña el consumo de carnes aumenta.

```{r}
ts_seasonal((dftimeserie), type="box")

```
Al graficar los valores respectivos de la variable asociados a cada mes, se tiene que la media para el mes de diciembre es ligeramente mayor. Para apreciar mejor esta diferencia, se elimina la tendencia en los datos y se realiza el grafico.

```{r}
ts_seasonal(diff(dftimeserie), type="box")

```
Ahora, es más claro que el mes de diciembre presenta un comportamiento por encima de la media. Esto implica que en dicho mes, se sacrifican mas cerdos. De manera analoga, enero se encuentra por debajo de la media general del proceso. Estos dos meses han de ser tenidos en cuenta.

```{r}
ts_heatmap(diff(dftimeserie), color = "Reds")
```

En el mapa, se tiene de izquiera a derecha, el mismo mes en diferentes años. Ahora, note que en diciembre, siempre se nota un mayor numero de sacrificios. 

Verticalmente se tiene un año representado. Por año, nuevamente diciembre siempre destaca por ser el mes con mayor numero de sacrificios. 

```{r}

ggseasonplot(dftimeserie, polar = TRUE)
```

Se tiene a  la derecha el conteo de años a partir del 2008,ahora; Cada año se encuentra graficado y espera ver estacionalidad en los datos. nuevamente, diciembre,destaca como mes con 'picos' 


## Modelamiento de la serie 

Para modelar apropiadamente la serie, se propone primero realziar un analisis descriptivo de la ACF y la PACF. Asi, pues: 

*ACF:*

```{r}
acf(df2$t_cabezas)
```

Note que debido a un decaimiento lento en la ACF, se ha de tomar en el modelo d>=1. Se procede entonces a tomar dicha diferencia y a graficar nuevamente la ACF.

```{r}
acf(df2$t_cabezas %>% diff %>% na.omit, lag.max = 50)
```

Al tomar diferencias para eliminar la tendencia, se nota que hay ruptura fuerte en los lags 1 y 12. Ahora, tenga presente que hay rupturas en otros lags, como 4 el. Esto en conjunto con la PACF permitirá entender cual seria el posible modelo a utilizar. Puesto que podrias ser muy subjetivo, podria entenderse como un corte en 4,8,11,12 (Destaca mucho mas),13. Ahora, tambien podria interpretarse como un comportamiento senoidal con ruptura en 12. Dado este escenario, se procede a graficar la PACF.

Ahora, la estacionalidad se ve marcada en 12. 

```{r}
pacf(df2$t_cabezas, lag.max = 35)
```
Al analizar la PACF, se percibe corte en los primeros lag (menos el 4) y en 8,11 y 12. Nuevamente, hay quien podria argumentar un comportamiento senoidal, por tanto se proponen modelos SARIMA(p,d,q)x(P,D,Q) para modelar la serie. Esto se realzia con la intencion de entender 

En definitiva, al analizar la ACF y la PACF, el modelo resultante ha de ser un SARIMA, donde la frecuencia asociada al mismo ha de ser 12.


## Modelando la serie: SARIMA vs auto.arima

Se procede a realizar un ajuste de un modelo para la serie con la funcion de auto.arima; se desea comparar los resultados de dicha funcion con los analisis descriptivos hasta el momento.

```{r}
mod1 = auto.arima(df2$t_cabezas, stepwise = F, approximation = F, seasonal = T,)
checkresiduals(mod1)
```

```{r}
par(mfrow=c(1,2))
plot(arroots(mod1),main="Inverse AR roots")
plot(maroots(mod1),main="Inverse MA roots")
```


La ACF de los residuales muestra correlacion en lag 12. Parece haber normalidad y a priori no se idenfitican datos atipicos. Ahora, tambien se aclara que la respectiva prueba de Ljung-Box rechaza no autocorrelacion. 

```{r}
shapiro.test(mod1$residuals)
```
La normalidad en los residuales no se cumple dado el test de shapiro-Wilk

```{r}

jarque.bera.test(mod1$residuals)
```
La normalidad en los residuales no se cumple dado el test de jarque-bera


```{r}
qqnorm(mod1$residuals)
qqline(mod1$residuals)
```

El grafico qq-plot parece no tener desviaciones fuertes, a exepcion del final del grafico. 

```{r}
summary(mod1)
```
Finalemente, auto.arima ajusta un modelo ARIMA (2,1,3); lo cual es contra intruitivo con el analisis estacional ya realizado. 

## Prediccion auto.arima

Se proponen realizar predicciones con los modelos teniendo en cuenta toda la base de datos, sin hacer Back-testing. Esto en aras de tener una mejor idea de que están haciendo los modelos y, si es o no un buen ajuste a los datos. Para profundizar esto, más adelante se utilizaran tecnicas de backtesting.

```{r}
# prediccion auto.arima

f_fit <- forecast(mod1)

autoplot(ts(df2$t_cabezas), series="Datos") + 
   autolayer(mod1$fitted, series="Modelo auto.arima ") +
   autolayer(f_fit, series="Prediction") +
   xlab("Year") + ylab("Total sacrificios (1/100.000)") + ggtitle("Total de sacrifios 2008-2022") + theme_bw()+theme(legend.title = element_blank(),legend.position = "bottom")

```

Note que, la funcion auto.arima ajusta un modelo ARIMA(2,1,3)
Ahora, se sabia con los analisis anteriores que la diferencia a tomar era 1 (d=1) y los valores de p y q podrian variar entre los mencionados. 
Ahora, tambien se sabia que la serie presentaba un comportamiento estacional. Sin embargo la funcion auto.arima NO muestra dicho comportamiento estacional en el modelamiento. 
Surge una pregunta, ¿Es este el mejor modelo, sin importar un analisis de estacionalidad? o, por otra parte, ¿ la funcion carece de ajuste sufiente para detectar un buen modelo?.

Para esto, se seleccionan diferentes modelos propuestos con la intencion de comparar sus valores y verificar cual tendria un mejor rendimiento.

NOTA: Se utiliza toda la base de datos por ahora, dado que se sospecha se realizarán intervenciones. Lo que en ultimas implica que las predicciones tienen sesgo. Mas adelante se divide entre datos de entrenamiento y datos de prueba para modeloar y predecir.

*Algunos modelos propuestos:*

Se proponen algunos modelos de manera manual. Esto con la idea de ilustrar que, al variar los parametros de los modelos; se pueden obtener diferentes AIC, BIC y en general, diferentes rendimientos. Luego, se calcula su AIC y BIC para contrastar cuales seran los mejores modelos. 

```{r}
x = df2$t_cabezas
mod2 = arima(x, order = c(0,1,1))
mod3 = arima(x, order = c(1,1,1))
mod4 = arima(x, order = c(1,1,2))
mod5 = arima(x, order = c(2,1,1))
mod6 = arima(x, order = c(2,1,2))
mod7 = arima(x, order = c(3,1,1))
mod8 = arima(x, order = c(3,1,2))
mod9 = arima(x, order = c(1,1,3))
mod10 = arima(x, order = c(3,1,3))

cbind(AIC(mod1,mod2,mod3,mod4,mod5,mod6,
mod7,mod8,mod9,mod10),BIC(mod1,mod2,mod3,mod4,mod5,mod6,
mod7,mod8,mod9,mod10)[2])

```

Como era de esperarse, auto.arima muestra un mejor rendimiento a la hora de escoger modelo de manera manual pero se sospecha, NO es el mejor modelo para ajustar los datos. 


## Seleccioonando mejor modelo

En un script a parte, se contrastan un total de 256 modelos (El archivo es de 8.8 mb) y para compilar el html, se presentan dificultades. De esta manera se empiezan a varias los parametros p,d,q, P,D,Q con estacionalidad en 12; para escoger de todos los posibles modelos resultantes, el mejor. 

```{r}
load('256modelos.Rdata')
```

Este archivo contiene el 'summary' de 256 modelos. De aqui, se obtiene despues de un procesamiento; los datos del modelo optimo segun ciertos criterios de seleccion.

Los codigos para ver como se calcula los modelos se encuentran *aqui*

*Modelo optimo segun AIC*

El modelo resultante con mejor rendimiento AIC y BIC no es necesariamente el modelo con un menor valor (Seria tan facil como buscar el minimo de toda la lista) pero, esto no es factible dado que se desea seguir el principio de parsimonia. Esto se menciona dado que el SARIMA optimo era de ordenes (3,1,4)x(4,1,1). Ahora, la diferencia en el ajuste respecto al seleccionado no era mayor.

Asi pues, el modelo resultante es un SARIMA (1,0,1)x(0,1,0); que presenta un buen rendimiento.

```{r}
prueba = Arima(dftimeserie, order = c(1,0,1),
               seasonal = list(order = c(0,1,0),period =12))
checkresiduals(prueba)
```
```{r}
par(mfrow=c(1,2))
plot(arroots(prueba),main="Inverse AR roots")
plot(maroots(prueba),main="Inverse MA roots")
```
Ahora, dicho modelo posee problemas en sus supuestos. Tiene correlacion en sus residuales y problemas de normalidad. 

```{r}
shapiro.test(prueba$residuals)
```
No normalidad segun Shapiro WIlk

```{r}
jarque.bera.test(prueba$residuals)
```

No normalidad, segun Jarque-Bera

```{r}
qqnorm(prueba$residuals)
qqline(prueba$residuals)
```
Desviaciones fuertes en el qqplot


```{r}
summary(prueba)
```

Al comparar diferentes medidas entre si, el modelo no necesariamente es el que tiene mejor RMSE, MAE, AIC o BIC. Sin embargo; la diferencia entre estos no era muy significativa y los ajustes son relativamente buenos. 

Finalmente, se procede a ajustar una prediccion con toda la base de datos dado este modelo. 

*Prediccion modelo seleccionado*

```{r}
f_fit <- forecast(prueba)
 autoplot(dftimeserie, series="Datos") + 
   autolayer(prueba$fitted, series="SARIMA(1,0,1)(0,1,0)[12] ") +
   autolayer(f_fit, series="Prediction") +
   xlab("Year") + ylab("Total sacrificios (1/100.000)") + ggtitle("Total de sacrifios 2008-2022") + theme_bw()+theme(legend.title = element_blank(),legend.position = "bottom")
```

Note que la prediccion del modelo de auto.arima es mas pobre. Esto dado que; hace falta realizar un ajuste de estacionalidad. Ahora, este modelo como es de esperarse, es mas preciso cuando la prediccion es mas cercana en el tiempo. 


*Holt-Winters 1.0*

Analogamente, se procede a realizar un ajuste con un modelo Holt-Winters para predecir. Dicho modelo es calculado con el siguiente codigo y, allí mismo se ajustan las predicciones.

Se modifican algunos parametros del modelo de Holt-Winters. Despues de realizar algunas pruebas se escoge el siguiente modelo: 

```{r}
# Custom HoltWinters fitting
HW2 <- hw(dftimeserie, alpha=0.2, beta=0.1, gamma=0.1)
```

Y las respectivas predicciones asociadas a dicho modelo son:

```{r}
HW2.pred <- forecast(HW2)
#Visually evaluate the prediction
autoplot(dftimeserie, series="Datos") + 
   autolayer(HW2$fitted, series="Modelo auto.arima ") +
   autolayer(HW2.pred, series="Prediction") +
   xlab("Year") + ylab("Total sacrificios (1/100.000)") + ggtitle("Total de sacrifios 2008-2022") + theme_bw()+theme(legend.title = element_blank(),legend.position = "bottom")
```

Note que existe una prediccion parecida a los modelos anteriores pero con IC mas amplios, por tanto; es mens precisa. 

*Modelo de Holt-Winters 2.0*

Se propone otro modelo con modelo con HW buscando los parametros optimos de manera automatica. 

```{r}
# Custom HoltWinters fitting
HW2ensayo <- hw(dftimeserie,  optim.start = c(alpha = 0, beta = 0, gamma = 0))
```

```{r}
HW2ensayo.pred <- forecast(HW2ensayo)
#Visually evaluate the prediction
autoplot(dftimeserie, series="Datos") + 
   autolayer(HW2ensayo$fitted, series="Modelo auto.arima ") +
   autolayer(HW2ensayo.pred, series="Prediction") +
   xlab("Year") + ylab("Total sacrificios (1/100.000)") + ggtitle("Total de sacrifios 2008-2022") + theme_bw()+theme(legend.title = element_blank(),legend.position = "bottom")
```
Note que ahora, el modelo tiene una prediccion mas coherente y un IC mas angosto. Falta preguntarse, ¿Cual es el mejor modelo? Pero, para responder a esta preguntaa se hace la siguiente comparacion.

## tabla de acurracy de modelos propuestos

Tabla resumen con los modelos propuestos.

```{r}
model_comp <- data.frame(accuracy(mod1)[1:6],
                         accuracy(prueba)[1:6],
                        accuracy(HW2)[1:6],
                        accuracy(HW2ensayo)[1:6],
                         row.names = c("ME", "RMSE",
                                       "MAE", "MPE",
                                       "MAPE","MASE"))
colnames(model_comp) <- c('auto.arima','Ajustado','HW1','HW2')

model_comp %>% kableExtra::kable() 
```

En general, los modelos que tienen mejor rendimiento son los HW 1 y 2. Se ha de escoger uno de ellos para modelar. Sin embargo, se deben realizar pruebas de backtesing para comparar. No necesariamente la tecnica es aplicable a todos los modelos pero, ¿por qué no probar?

## Back-Testing

Para modelar correctamente, se utilza back-testing; aqui se divide en datos de entrenamiento y prueba.
Se trabajara con el 80% de los datos. Asi pues:

```{r}

df3 = df2[,1:2] # serie con la que se trabajará
n = df3$t_cabezas %>% length() # 168 observaciones
split = (n*0.8) %>% round() # se toman 134 datos
indice = df3[split,] # Fecha dividida hasta el 2019

# Division datos de entrenamiento
train = df3[1:split,] #134 datos

# Division datos de prueba
test = df3[(split+1):nrow(df3),] # 34 datos


```

## Grafica datos entrenamiento y prueba:

```{r}
serie.original = df2$t_cabezas
#prediccions = as.data.frame(prediccions)
s1 = train$t_cabezas # termina en septiembre del 2022 DATOS DE ENTRENAMIENTO
s2 = test$t_cabezas #

a1 = ts(s1, frequency = 12, start = c(2008,10))# ENTRENAMIENTO
a2 = ts(s2, frequency = 12, start = end(a1)) # PRUEBA

#Visually evaluate the prediction
autoplot(a1, series="Datos entrenamiento") + 
   autolayer(a2, series="Datos de prueba") +
   #autolayer(HW2.pred, series="Prediction") +
   xlab("Year") + ylab("Total sacrificios (1/100.000)") + ggtitle("Total de sacrifios 2008-2022") + theme_bw()+theme(legend.title = element_blank(),legend.position = "bottom")
```

Con la base de datos dividida, se procede a analizar el ajuste de los modelos via Back-Testing.

## Modelos con Back-Testing

Todos los modelos utilizados en la serie anterior, se utilizan para predecir ahora; evaluarlos via back-Testing. 

```{r echo=FALSE}
mod1 = auto.arima(s1, stepwise = F, approximation = F, seasonal = T,) # ARIMA(0,1,5)
mod2 = Arima(s1, order = c(1,0,1),
               seasonal = list(order = c(0,1,0),period =12)) # SARIMA (1,0,1)x(0,1,0)
mod3 <- hw(ts(train$t_cabezas, frequency = 12, start = c(2008,10)), alpha=0.2, beta=0.1, gamma=0.1,h = 34)
mod4 <- hw(ts(train$t_cabezas, frequency = 12, start = c(2008,10)),  optim.start = c(alpha = 0, beta = 0, gamma = 0), h=34)
```
Para calcular el modelo con mejor rendimiento, se procede a calcular el MSE asociado a cada modelo. De esta manera:

```{r}
# PREGUNTAR SI ES ASI
y = test$t_cabezas # valor de y_test; reales

a1 = forecast(mod1,h = 34) # prediccion modelo 1
y_hat1 = a1$mean

a2 = forecast(mod2,h=34)  # prediccion modelo 2
y_hat2 = a2$mean

a3 = mod3  # prediccion modelo 3 
y_hat3 = a3$mean

a4 <- mod4 # prediccion modelo 4
y_hat4 <- a4$mean
```

```{r}
mse1 = mean((y-y_hat1))^2
mse2 = mean((y-y_hat2))^2
mse3 = mean((y-y_hat3))^2
mse4 = mean((y-y_hat4))^2
```


```{r echo=FALSE}
tabla = cbind(c(mse1,mse2,mse3,mse4))
colnames(tabla) = c("MSE")
rownames(tabla) = c("Modelo 1","Modelo 2","Modelo 3","Modelo 4")
tabla %>% kable
```

De esta manera, entonces; el modelo optimo será el que tenga un menor MSE. El modelo con mejor rendimiendo es el modelo 4, que respectivamente corresponde al modelo con menor MSE. 

Se adjuntan las siguientes metricas para la seleccion ideal del modelo.

```{r}
model_comp <- data.frame(accuracy(mod1)[1:6],
                         accuracy(mod2)[1:6],
                        accuracy(mod3)[1:6],
                        accuracy(mod4)[1:6],
                         row.names = c("ME", "RMSE",
                                       "MAE", "MPE",
                                       "MAPE","MASE"))
colnames(model_comp) <- c('Modelo 1','Modelo 2','Modelo 3','Modelo 4')

model_comp %>% kableExtra::kable() 
```
Segunla anterior tabla, el modelo con mejor rendimiento es el modelo 4. Se muestra acontinuacion.

```{r}
mod4$model
```

Este es un modelo Holt-Winters con los parametros anteriores.Ahora, como este modelo no tiene supuestos de normalidad en los residuales...
Pues bastaria lanzar una prediccion. 

```{r}
# prediccion HW

f_fit <- y_hat4

autoplot(dftimeserie, series="Datos") + 
   autolayer(mod4$fitted, series="Modelo HW fitted ") +
   autolayer(f_fit, series="Prediction") +
   #autolayer()+
   xlab("Year") + ylab("Total sacrificios (1/100.000)") + ggtitle("Total de sacrifios 2008-2022") + theme_bw()+theme(legend.title = element_blank(),legend.position = "bottom")

```

En el grafico anterior, se tiene los datos en rojo, los ajustados por el modelo HW en verde u finalmente la prediccion para los datos de prueba. No se grafica el IC dado que puede ser caotico para visualizar. Ahora, dicho grafico seria:

```{r}
f_fit <- forecast(mod4,h=34)
autoplot(dftimeserie, series="Datos") + 
   #autolayer(mod4$fitted, series="Modelo HW fitted ") +
   autolayer(f_fit, series="Prediction") +
   #autolayer()+
   xlab("Year") + ylab("Total sacrificios (1/100.000)") + ggtitle("Total de sacrifios 2008-2022") + theme_bw()+theme(legend.title = element_blank(),legend.position = "bottom")

```

Ahora, acá se tienen los datos reales en rojo y solo la prediccion. Note como el modelo tiene peor rendimiento que cuando se ajusta con la totalidad de la base de datos. Sin embargo, el ajuste de la serie predicha por el modelo no es necesariamente malo. AHora, recuerde que entre mas predicciones en el tiempo se hagan, mas imprecisa es la prediccion. 



## Analisis de outliers

Observe de nuevo la serie original. Con esta serie se busca entonces entender si existe un comportamiento de datos atipicos. Ahora, note que:

```{r echo=FALSE}
plot(dftimeserie)
```
De manera descriptiva se oberva que para el año 2020 se tiene una caida mas pronunciada. Se desea observar si para dicho dato existe evidencia de ser un outlier.

La funcion tso del paquete tsoutliers permite analizar los datos atipicos de una serie de tiempo. 

*Modelo de Outliers*

```{r}
mod_outliers <- tso(dftimeserie, delta=0.7)

mod_outliers 
```

Por defecto, el modelo de los outliers deja fijado un delta de 0.7; se propone variar el delta para empezar a detectar cuales son los outliers detectados al variar delta. Dado el coste computacional, se definen deltas menores a 0.9 con saltos de 0.1

Note que el modelo seleccionado via 256 modelos, es el mismo que selecciona automaticamente la funcion tso.


```{r}
# Modelos aplicados de esta forma por menos coste computacional
mod_outliers0 <- tso(dftimeserie, delta=0)
mod_outliers1<- tso(dftimeserie, delta=0.1)
mod_outliers2 <- tso(dftimeserie, delta=0.2)
mod_outliers3<- tso(dftimeserie, delta=0.3)
mod_outliers4 <- tso(dftimeserie, delta=0.4)
mod_outliers5 <- tso(dftimeserie, delta=0.5)
mod_outliers6 <- tso(dftimeserie, delta=0.6)
mod_outliers7 <- tso(dftimeserie, delta=0.7)
mod_outliers8 <- tso(dftimeserie, delta=0.8)
mod_outliers9 <- tso(dftimeserie, delta=0.9)
mod_outliers10 <- tso(dftimeserie, delta=1)

```

```{r echo=FALSE}
mod_outliers0$outliers %>% kable(label = 'Delta 0')
```

```{r echo=FALSE}
mod_outliers1$outliers %>% kable(label = 'Delta 1')
```

```{r echo=FALSE}
mod_outliers2$outliers %>% kable(label = 'Delta 2')
```
```{r echo=FALSE}
mod_outliers3$outliers %>% kable(label = 'Delta 3')
```
```{r echo=FALSE}
mod_outliers4$outliers %>% kable(label = 'Delta 4')
```
```{r echo=FALSE}
mod_outliers5$outliers %>% kable(label = 'Delta 5')
```
```{r echo=FALSE}
mod_outliers6$outliers %>% kable(label = 'Delta 6')
```
```{r echo=FALSE}
mod_outliers7$outliers %>% kable(label = 'Delta 7')
```
```{r echo=FALSE}
mod_outliers8$outliers %>% kable(label = 'Delta 8')
```
```{r echo=FALSE}
mod_outliers9$outliers %>% kable(label = 'Delta 9')
```
```{r echo=FALSE}
mod_outliers10$outliers %>% kable(label = 'Delta 10')
```
Note que de manera general, los modelos hasta un delta de 0.6 identifican a la observacion 139 como un dato atipico. Este dato coincide con Marzo del 2020, en cual se declara pandemia. Por este motivo, se podria esperar que la observacion 139 sea un dato atipico AO, es decir; afectó momentaneamente la serie de tiempo y luego esta se normalizó. Por tal motivo se concluye que se ha de modelar con una funcion pulso. 

Ahora, al variar el parametro, aparecen otros outliers e incluso el 139 es detectado como otro tipo de outlier, sin embargo; todos los otros no tuvieron causas asignables para ser dictaminados como datos atipicos por variables exogemas; asi que se opta por aplicarle una funcion pulso. 

## Intervencion

Se procede a dividir la serie antes de la intervencion. Esto se selecciona basado en una idea muy simple; posiblemente la pandemia pudo afectar el numero de sacrificios mensuales. En la serie, es el dato 139 el cal corresponde a marzo del 2020 (donde se evidencia la caida).

```{r echo=FALSE}
ensayointervencio <- window(dftimeserie, start=time(dftimeserie)[1],
                end = time(dftimeserie)[138])
paco = ensayointervencio %>% auto.arima(stepwise = F,approximation = F) 
paco %>% summary()
```

Finalmente, se tiene que los ordenes del modelo con auto.arima; asi pues, se tiene un ARIMA(3,0,0)(0,1,2)[12]; para un modelo ajustado antes de la intervencion. 

Entonces, este es el modelo con la intervencion a la observacion 139.

## *Funcion pulso:*

```{r}
modelo1superintervencion <- arimax(dftimeserie, order=c(3, 0, 0),seasonal = list(order = c(0, 1, 2)),
xtransf=data.frame( creemosquepandemia=1 *(seq_along(dftimeserie) == 139)),
transfer=list(c(1, 0)))
modelo1superintervencion %>% coeftest()
```

Dada esta tabla, se busca entender cual de los coeficientes son o no significativos. 

Entonces, como el AR1 NO es significativo; se concluye que la funcion a utilizar es una funcion pulso. Dicho de otra manera (Mas bonita):

El δ1 estimado (0.034201x100.000 =3420.1 ) no es significativo con un nivel de significancia del 5 %. En cambio, el ω1 estimado (-0.692464x100000=-69246.4 ) sí es significativo; lo que implica que la caida dada por pandemia es de cerca de 69246 cabezas de marranos.

En pocas palabras, la pandemia afectó en promedio la produccion de cabezas porcinas en casi 70 mil unidades menos de lo que se producia normalmente. 

```{r}
modelo1superintervencion2 <- arimax(dftimeserie, order=c(3, 0, 0),seasonal = list(order = c(0, 1, 2)),
xtransf=data.frame( creemosquepandemia=1 *(seq_along(dftimeserie) == 139)),

transfer=list(c(0, 0)))
modelo1superintervencion2 %>% coeftest()
```

Finalmente, al analizar los datos realizando la intervencion, se concluye que el modelo es significativo en todos sus parametros entonces; se procede a predecir con dicho modelo intervenido.

## Prediccion con modelo intervenido. 

Para realizar las predicciones con el modelo intervenido, se ha de revisar los supuestos del modelo. Entonces:

```{r}
modelo1superintervencion2 %>% checkresiduals()
```

Al analizar de manera descriptiva, el modelo parece seguir una distribucion normal, la ACF detecta autocorrelacion y, parece que los errores tienen  problemas de autocorrelacion.

Respecto a outliers, se detectan algunos puntos marcados pero no tienen asociados  causas asignables.

Varianza constante (en principio); Por otra parte, se observa que la prueba de correlacion de los residuales de Ljung-Box determina correlacion en los residuales. 

Aun asi, dada las condiciones del modelo se decide *NO* intervenir nuevamente, puesto que se podria sobreajustar. 

*Normalidad residuales:*

```{r echo=FALSE}
modelo1superintervencion2$residuals %>% shapiro.test()
```
Note que, aunque asi lo parezca; los errores segun la prueba de shapiro-wilk no son normales. Se procede a analizar el qqplot.

```{r echo=FALSE}
qqnorm(modelo1superintervencion2$residuals)
qqline(modelo1superintervencion2$residuals)
```

Note que los residuales tienen en general un buen ajuste a la recta de normalidad. El qqplot tiene algunos datos atipicos. 

## Prediciones con modelo intervenido

Finalmente, se procede a realizar las predicciones con el modelo intervenido.

A continuacion se muestra el modelo intervenido.

```{r echo=FALSE}
modelo1superintervencion2
```

```{r}

reg1 <- stats::filter(1 * (seq.int(length(dftimeserie) + 12)== 139),

filter =0, method = "rec",
sides = 1)
xreg <- cbind(I1=stats::filter(1*(seq_along(dftimeserie) == 139),method = "rec",sides = 1,filter = 0))

modelo_intervenido <-arima(dftimeserie, order = c(3,0, 0),
seasonal = list(order = c(0,1,2),
period = 12), xreg = xreg)
```

```{r}
modelo_intervenido %>% coeftest()
```
Note que para cada parametro del modelo, se tiene que son significativos.

```{r message=FALSE, warning=FALSE}
df2$t_cabezas=df2$t_cabezas
vectores <- c(df2$t_cabezas)
dftimeserie <-ts(vectores, frequency = 12, start = c(2008,10))
reg1 <- ts(reg1, start = start(dftimeserie),
frequency = frequency(dftimeserie)) # hasta aca se tiene 0 y 1 en la intervencion
reg1_new <- window(reg1, start = c(2022,09), end = c(2023,08))

inter.pred = predict(modelo_intervenido, newxreg=reg1_new, n.ahead=12)
inter.pred # Estas son las predicciones
```

```{r}
prediccions = inter.pred$pred # serie de tiempo de la prediccion
se = inter.pred$se # para crear los IC
```

```{r}
MSE = mean((df2$t_cabezas- fitted.values(modelo_intervenido)))^2
MSE
```
El MSE de este modelo es del orden de 0.000007387; Hasta el momento, ningun modelo ha ajustado un MSE tan pequeño.
De esta manera, este modelo con intervenciones; parece el modelo mas confiable para realizar predicciones.

# Grafica de la prediccion

```{r}
serie.original = df2$t_cabezas
prediccions = as.data.frame(prediccions)
s1 = df2$t_cabezas # termina en septiembre del 2022
s2 = prediccions #

a1 = ts(s1, frequency = 12, start = c(2008,10))
a2 = ts(s2, frequency = 12, start = c(2022,09))

#Visually evaluate the prediction
autoplot(a1, series="Datos") + 
   autolayer(a2, series="Predicciones") +
   #autolayer(HW2.pred, series="Prediction") +
   xlab("Year") + ylab("Total sacrificios (1/100.000)") + ggtitle("Total de sacrifios 2008-2022") + theme_bw()+theme(legend.title = element_blank(),legend.position = "bottom")
```

Finalmente, se tienen las predicciones con su respectivo IC.


