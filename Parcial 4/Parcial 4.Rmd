---
title: "Series de tiempo - Parcial 4"
author: "Felipe Lopera & Jhonatan Smith"
date: "2022-10-09"
output: rmdformats::readthedown
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r message=FALSE, warning=FALSE, include=FALSE}
require(dplyr)
require(lmtest)
require(tseries)
require(TSA)
require(astsa)
require(tsoutliers)
require(kableExtra)
require(tidyverse)
require(ggplot2)
require(hrbrthemes)
require(tsoutliers)
require(TSstudio)
require(forecast)
require(latticeExtra)
require(datetime)
library(lubridate)
require(forecast)
library(readxl)
require(forecast)
require(readr)
require(janitor)
```


```{r include=FALSE}

# fn para calcular las raices unitarias y graficas bien chimbita
arroots <- function(object)
{
  if(!("Arima" %in% class(object)) &
     !("ar" %in% class(object)))
    stop("object must be of class Arima or ar")
  if("Arima" %in% class(object))
    parvec <- object$model$phi
  else
    parvec <- object$ar
  if(length(parvec) > 0)
  {
    last.nonzero <- max(which(abs(parvec) > 1e-08))
    if (last.nonzero > 0)
      return(structure(list(
          roots=polyroot(c(1,-parvec[1:last.nonzero])),
          type="AR"),
        class='armaroots'))
  }
  return(structure(list(roots=numeric(0), type="AR"),
    class='armaroots'))
}

# Compute MA roots
maroots <- function(object)
{
  if(!("Arima" %in% class(object)))
    stop("object must be of class Arima")
  parvec <- object$model$theta
  if(length(parvec) > 0)
  {
    last.nonzero <- max(which(abs(parvec) > 1e-08))
    if (last.nonzero > 0)
      return(structure(list(
          roots=polyroot(c(1,parvec[1:last.nonzero])),
          type="MA"),
        class='armaroots'))
  }
  return(structure(list(roots=numeric(0), type="MA"),
    class='armaroots'))
}

plot.armaroots <- function(x, xlab="Real", ylab="Imaginary",
    main=paste("Inverse roots of", x$type,
          "characteristic polynomial"),
    ...)
{
  oldpar <- par(pty='s')
  on.exit(par(oldpar))
  plot(c(-1,1), c(-1,1), xlab=xlab, ylab=ylab,
       type="n", bty="n", xaxt="n", yaxt="n", main=main, ...)
  axis(1, at=c(-1,0,1), line=0.5, tck=-0.025)
  axis(2, at=c(-1,0,1), label=c("-i","0","i"),
    line=0.5, tck=-0.025)
  circx <- seq(-1,1,l=501)
  circy <- sqrt(1-circx^2)
  lines(c(circx,circx), c(circy,-circy), col='gray')
  lines(c(-2,2), c(0,0), col='gray')
  lines(c(0,0), c(-2,2), col='gray')
  if(length(x$roots) > 0)
  {
    inside <- abs(x$roots) > 1
    points(1/x$roots[inside], pch=19, col='black')
    if(sum(!inside) > 0)
      points(1/x$roots[!inside], pch=19, col='red')
  }
}
```

## Marco teorico: ¿Por qué los cerditos?

![Un lindo cerdito](C:/Users\jhsga\OneDrive\Escritorio\ODINSA\Parcial-4-series-de-tiempo\Parcial 4\tierno.jpg)

Tenga presente que el análisis del consumo cárnico para una población es importante puesto que a las entidades gubernamentales le permite controlar y entender dicho comportamiento para identificar y prever posibles problemas de salud pública o en su defecto, generar políticas para controlar la economía del consumo. Se entiende pues, que un análisis para con el consumo es de vital importancia para los análisis demográficos de una población. 

También, tener un control total sobre la cantidad de cerdos sacrificados, ayuda a las entidades sanitarias a mantener un estándar en dicha producción. Si esto no es regulado, se pueden propagar enfermedades por la mala praxis en la industria.

En el presente análisis, se desea predecir el número total de cabezas porcinas sacrificadas.


## PERO AUN MAS IMPORTANTE:

![Una chuleta](C:/Users\jhsga\OneDrive\Escritorio\ODINSA\Parcial-4-series-de-tiempo\Parcial 4\chuleta.jpg)

El factor económico y sabroso del asunto.. 

## Procesamiento de la base de datos

El primer paso es la lectura de los datos. Dado que los nombres de la serie se encuentran inapropiados para trabajar con ellos, se corrigen los mismos después de leer la base de datos.

Se tiene en el DANE una base de datos con el registro nacional de sacrificios cárnicos, para este caso; porcinos.


```{r include=FALSE}
cerditos_2_la_venganza <- read_excel("cerditos 2 la venganza.xls", 
    sheet = "Cuadro 3", skip = 9)
df2 =cerditos_2_la_venganza 


df2 = cerditos_2_la_venganza
df2 = df2 %>% clean_names()
```


```{r }
df2 %>% head(3)

```

La base de datos 2 (df2) corresponde a los análisis totales de cabezas porcinas sacrificadas. Con esto en mente, se tienen datos desde el 2008 hasta el 2022 con las respectivas variables. La escala de la variable es en cientos de miles. Se baja la escala para hacer más interpretable las gráficas.  

## Grafico sacrificios por Machos y Hembras


```{r}
df2$t_cabezas = df2$t_cabezas/100000
df2$machos = df2$machos/100000
df2$hembras = df2$hembras/100000
# --> construct separate plots for each series
obj1 <- xyplot(machos ~ fecha, df2, type = "l" , lwd=2)
obj2 <- xyplot(hembras ~ fecha, df2, type = "l", lwd=2)
 
# --> Make the plot with second y axis AND legend:
doubleYScale(obj1, obj2, text = c("sacrificios porcinos machos", "sacrificio porcinos hembras") , add.ylab2 = TRUE)
```
De manera análoga, se observa como el comportamiento en el tiempo de ambas series (Sacrificios de machos y de hembras) es similar.

```{r echo=FALSE, message=FALSE, warning=FALSE}

x = df2$fecha
y = df2$t_cabezas

# plot 

ggplot(df2, aes(x=fecha,y=t_cabezas))+
  geom_line(color = '#69b3a2', size = 1, alpha = 0.9)+
  theme_ipsum()+
  ggtitle('Total de sacrificios porcinos')

```
## Análisis descriptivos para la serie: 

Una vez graficada la serie, se proceden a realizar análisis descriptivos que permitan ver mejor el comportamiento general de la serie.


```{r}
df2$t_cabezas=df2$t_cabezas
vectores <- c(df2$t_cabezas)
dftimeserie <-ts(vectores, frequency = 12, start = c(2008,10))
descompuesta=decompose(dftimeserie)
plot(descompuesta)

```

Para la serie, se hace una descomposición aditiva de los datos. Estos revelan que:

 1) Hay tendencia creciente en la serie
 
 2) Hay estacionalidad en los datos (En principio, anual)
 
 3) Existe un dato atípico (en principio, se sospecha pandemia) en el gráfico de seasonal decompose, puesto que se ve un pico en el año '13'(Que representa el año 2008+13, es decir; 2021)
 
 El siguiente grafico permite ver de manera más clara la estacionalidad.


```{r}
ggseasonplot(dftimeserie,year.labels=TRUE,continuous=TRUE)
```
Con una escala de 100.000 cerdos sacrificados por cada unidad representada, se tiene que el mes de diciembre destaca por tener un mayor número de sacrificios en su respectivo año. Para este caso, se puede deducir una estacionalidad anual en dicho mes. Se debe ahondar en el fenómeno para entender por qué en diciembre se sacrifican más cerdos. Ahora, el sentido común apunta a que, en vísperas de época navideña el consumo de carnes aumenta.

```{r}
ts_seasonal((dftimeserie), type="box")

```
Al graficar los valores respectivos de la variable asociados a cada mes, se tiene que la media para el mes de diciembre es ligeramente mayor. Para apreciar mejor esta diferencia, se elimina la tendencia en los datos y se realiza el grafico.



```{r}
ts_heatmap((dftimeserie), color = "Reds")
```

En el mapa, se tiene de izquierda a derecha, el mismo mes en diferentes años. Ahora, note que, en diciembre, siempre se nota un mayor número de sacrificios. 

Verticalmente se tiene un año representado. Por año, nuevamente diciembre siempre destaca por ser el mes con mayor número de sacrificios.


```{r}

ggseasonplot(dftimeserie, polar = TRUE)
```

Se tiene a la derecha el conteo de años a partir del 2008, ahora; Cada año se encuentra graficado y espera ver estacionalidad en los datos. nuevamente, diciembre, destaca como mes con 'picos' 


## Modelamiento de la serie 

Para modelar apropiadamente la serie, se propone primero realizar un análisis descriptivo de la ACF y la PACF. Así, pues: 

*ACF:*


```{r}
acf(df2$t_cabezas)
```

Note que, debido a un decaimiento lento en la ACF, se ha de tomar en el modelo d>=1. Se procede entonces a tomar dicha diferencia y a graficar nuevamente la ACF.


```{r}
acf(df2$t_cabezas %>% diff %>% na.omit, lag.max = 50)
```

Al tomar diferencias para eliminar la tendencia, se nota que hay ruptura fuerte en los lags 1 y 12. Ahora, tenga presente que hay rupturas en otros lags, como 4 el. Esto en conjunto con la PACF permitirá entender cuál sería el posible modelo para utilizar. Puesto que podría ser muy subjetivo, podría entenderse como un corte en 4,8,11,12 (Destaca mucho más),13. Ahora, también podría interpretarse como un comportamiento senoidal con ruptura en 12. Dado este escenario, se procede a graficar la PACF.

Ahora, la estacionalidad se ve marcada en 12.
 

```{r}
pacf(df2$t_cabezas, lag.max = 35)
```
Al analizar la PACF, se percibe corte en los primeros lag (menos el 4) y en 8,11 y 12. Nuevamente, hay quien podría argumentar un comportamiento senoidal, por tanto se proponen modelos SARIMA(p,d,q)x(P,D,Q) para modelar la serie. Esto se realiza con la intención de entender en definitiva, al analizar la ACF y la PACF, el modelo resultante ha de ser un SARIMA, donde la frecuencia asociada al mismo ha de ser 12.


## Modelando la serie: SARIMA vs auto.arima

Se procede a realizar un ajuste de un modelo para la serie con la función de auto.arima; se desea comparar los resultados de dicha función con los análisis descriptivos hasta el momento.


```{r}
mod1 = auto.arima(ts(df2$t_cabezas,frequency = 12, start = c(2008,10)), stepwise = F, approximation = F, seasonal = T,)
checkresiduals(mod1)
```
La ACF de los residuales muestra correlación en lag 12. Parece haber normalidad y a priori se identifican datos atípicos. Ahora, también se aclara que la respectiva prueba de Ljung-Box rechaza no autocorrelación. Note el grafico de la ACF, no se rechaza la prueba pero si hay correlacion de ordenes mayores.


```{r}
shapiro.test(mod1$residuals)
```
La normalidad en los residuales no se cumple dado el test de shapiro-Wilk

```{r}

jarque.bera.test(mod1$residuals)
```
La normalidad en los residuales no se cumple dado el test de jarque-bera


```{r}
qqnorm(mod1$residuals)
qqline(mod1$residuals)
```

El grafico QQ-plot parece tener desviaciones fuertes, sobretodo en las colas del grafico. Se ha de dictaminar si corresponden a datos atipicos o si han de ser modelados de manera diferente.

```{r}
par(mfrow=c(1,2))
plot(arroots(mod1),main="Inverse AR roots")
plot(maroots(mod1),main="Inverse MA roots")
```

Se tiene el graifico del inverso de las raices del circulo unitario. Una mera curiosidad. 

```{r}
summary(mod1)
```
Finalmente, auto.arima ajusta un modelo ARIMA (2,1,3); lo cual es contra intuitivo con el análisis estacional ya realizado. 

## Predicción auto.arima

Se proponen realizar predicciones con los modelos teniendo en cuenta toda la base de datos, sin hacer Back-testing. Esto en aras de tener una mejor idea de que están haciendo los modelos y, si es o no un buen ajuste a los datos. Para profundizar esto, más adelante se utilizarán técnicas de backtesting.


```{r}
# prediccion auto.arima

f_fit <- forecast(mod1)

autoplot(ts(df2$t_cabezas, frequency = 12, start = c(2008,10)), series="Datos") + 
   autolayer(mod1$fitted, series="Modelo auto.arima ") +
   autolayer(f_fit, series="Prediction") +
   xlab("Year") + ylab("Total sacrificios (1/100.000)") + ggtitle("Total de sacrifios 2008-2022") + theme_bw()+theme(legend.title = element_blank(),legend.position = "bottom")

```

Note que, la función auto.arima ajusta un modelo (1,0,1)(2,1,1)[12]

NOTA: Se utiliza toda la base de datos por ahora, dado que se sospecha se realizarán intervenciones. Lo que en ultimas implica que las predicciones tienen sesgo. Mas adelante se divide entre datos de entrenamiento y datos de prueba para modelar y predecir.

Como era de esperarse, auto.arima muestra un mejor rendimiento a la hora de escoger modelo pero se sospecha, NO es el mejor modelo para ajustar los datos. 


*Holt-Winters 1.0*

Análogamente, se procede a realizar un ajuste con un modelo Holt-Winters para predecir. Dicho modelo es calculado con el siguiente código y, allí mismo se ajustan las predicciones.

Se modifican algunos parámetros del modelo de Holt-Winters. Después de realizar algunas pruebas se escoge el siguiente modelo:

```{r}
# Custom HoltWinters fitting
HW2 <- hw(dftimeserie, alpha=0.2, beta=0.1, gamma=0.1)
```

Y las respectivas predicciones asociadas a dicho modelo son:

```{r}
HW2.pred <- forecast(HW2)
#Visually evaluate the prediction
autoplot(dftimeserie, series="Datos") + 
   autolayer(HW2$fitted, series="Modelo auto.arima ") +
   autolayer(HW2.pred, series="Prediction") +
   xlab("Year") + ylab("Total sacrificios (1/100.000)") + ggtitle("Total de sacrifios 2008-2022") + theme_bw()+theme(legend.title = element_blank(),legend.position = "bottom")
```

Note que existe una predicción parecida a los modelos anteriores pero con IC más amplios, por tanto; es menos precisa. 

*Modelo de Holt-Winters 2.0*

Se propone otro modelo con modelo con HW buscando los parámetros óptimos de manera automática.

```{r}
# Custom HoltWinters fitting
HW2ensayo <- hw(dftimeserie,  optim.start = c(alpha = 0, beta = 0, gamma = 0))
```

```{r}
HW2ensayo.pred <- forecast(HW2ensayo)
#Visually evaluate the prediction
autoplot(dftimeserie, series="Datos") + 
   autolayer(HW2ensayo$fitted, series="Modelo auto.arima ") +
   autolayer(HW2ensayo.pred, series="Prediction") +
   xlab("Year") + ylab("Total sacrificios (1/100.000)") + ggtitle("Total de sacrifios 2008-2022") + theme_bw()+theme(legend.title = element_blank(),legend.position = "bottom")
```
Note que ahora, el modelo tiene una predicción más coherente y un IC más angosto. Falta preguntarse, ¿Cuál es el mejor modelo? Pero, para responder a esta pregunta se hace la siguiente comparación.

## tabla de acurracy de modelos propuestos

Tabla resumen con los modelos propuestos.


```{r}
model_comp <- data.frame(accuracy(mod1)[1:6],
                        accuracy(HW2)[1:6],
                        accuracy(HW2ensayo)[1:6],
                         row.names = c("ME", "RMSE",
                                       "MAE", "MPE",
                                       "MAPE","MASE"))
colnames(model_comp) <- c('auto.arima','HW1','HW2')

model_comp %>% kableExtra::kable() 
```

En general, auto.arima tiene mejor rendimiento. Se ha de escoger uno de ellos para modelar. Sin embargo, se deben realizar pruebas de backtesing para comparar. No necesariamente la técnica es aplicable a todos los modelos, pero, ¿por qué no probar? Se esperaria que despues de realizado este proceso con toda la base de datos (sobreparametrizando), auto.arima tenga un mejor rendimiento. 

## Back-Testing

Para modelar correctamente, se utiliza back-testing; aquí se divide en datos de entrenamiento y prueba.
Se trabajará con el 80% de los datos. Así pues:


```{r}

df3 = df2[,1:2] # serie con la que se trabajará
n = df3$t_cabezas %>% length() # 168 observaciones
split = (n*0.8) %>% round() # se toman 134 datos
indice = df3[split,] # Fecha dividida hasta el 2019

# Division datos de entrenamiento
train = df3[1:split,] #134 datos

# Division datos de prueba
test = df3[(split+1):nrow(df3),] # 34 datos


```

## Grafica datos entrenamiento y prueba:

```{r}
s1 = train$t_cabezas # termina en septiembre del 2022 DATOS DE ENTRENAMIENTO
s2 = test$t_cabezas #

a1 = ts(s1, frequency = 12, start = c(2008,10))# ENTRENAMIENTO
a2 = ts(s2, frequency = 12, start = end(a1)) # PRUEBA

#Grafico datos de Train y Test

autoplot(a1, series="Datos entrenamiento") + 
   autolayer(a2, series="Datos de prueba") +
   #autolayer(HW2.pred, series="Prediction") +
   xlab("Year") + ylab("Total sacrificios (1/100.000)") + ggtitle("Total de sacrifios 2008-2022") + theme_bw()+theme(legend.title = element_blank(),legend.position = "bottom")
```

Con la base de datos dividida, se procede a analizar el ajuste de los modelos vía Back-Testing.

*Modelos con Back-Testing*

Todos los modelos utilizados en la serie anterior se utilizan para predecir ahora; evaluarlos vía back-Testing.


```{r echo=FALSE}
mod1 = auto.arima(a1, stepwise = F, approximation = F) # Auto.arima
mod2 <- hw(a1, alpha=0.2, beta=0.1, gamma=0.1,h = 34) # HW 1
mod3 <- hw(a1,  optim.start = c(alpha = 0, beta = 0, gamma = 0), h=34) # HW 2
```


Para calcular el modelo con mejor rendimiento, se procede a calcular el MSE y el RMSE asociado a cada modelo. De esta manera:

```{r echo=FALSE}

y = test$t_cabezas # valor de y_test; reales

p1 = forecast(mod1,h = 34) # prediccion modelo 1
y_hat1 = p1$mean

p2 = forecast(mod2,h=34)  # prediccion modelo 2
y_hat2 = p2$mean

p3 = mod3  # prediccion modelo 3 
y_hat3 = p3$mean


# MSE PREDICCIONES DATOS DE PRUEBA
mse1 = mean((y-y_hat1))^2
mse2 = mean((y-y_hat2))^2
mse3 = mean((y-y_hat3))^2

# RMSE PREDICCIONES DATOS DE PRUEBA

rmse1 = mse1 %>% sqrt()
rmse2 = mse2 %>% sqrt()
rmse3 = mse3 %>% sqrt()

mse = c(mse1,mse2,mse3)
rmse = c(rmse1,rmse2,rmse3)

tabla = cbind(mse, rmse)
colnames(tabla) = c("MSE", 'RMSE')
rownames(tabla) = c("Modelo 1","Modelo 2","Modelo 3")
tabla %>% kable
```

En este caso, el modelo con mejor rendimiento segun el MSE y RMSE es el modelo 1; modelo construido con la funcion auto.arima

## El mejor modelo: auto.arima lo hace de nuevo

Y en efecto, el mejor modelo es el de la funcion auto.arima

```{r}
mod1 %>% summary()
```

Se ha de revisar los supuestos de dicho modelo. Entonces:

```{r}
mod1 %>% checkresiduals()
```
En principio no hay problema de autocorrelacion en los residuales segun la prueba. 

La ACF muestra coorrelacion de lag 27. No se hace significativa para este caso. 

```{r}
shapiro.test(mod1$residuals)
```

Y son 'casi' normales. Casi... De hecho y como nos mencionaron reiterativamente en clase, a un nivel de significancia de 4% es normal so...

No sea terco y aplique una transformacion a los datos. Quizas, depronto, uno nunca sabe, ojalá, dios mediante, sean normales. Pero antes;
el qq-plot

```{r}
qqnorm(mod1$residuals)
qqline(mod1$residuals)
```
Se podria sospechar que es mas un problema de outliers que de transformaciones en los datos. Ajustemos el mismo modelo pero, con el logaritmo de los datos. 

```{r}
autoarima.la.venganza = auto.arima(log(a1), stepwise = F,approximation = F)
```

```{r}
autoarima.la.venganza%>% summary()
```

```{r}
qqnorm(autoarima.la.venganza$residuals)
qqline(autoarima.la.venganza$residuals)
```


```{r}
modelo2 = arima(x = a1 %>% log, order = c(3,0,0), seasonal = c(0,1,2))
```

```{r}
qqnorm(modelo2$residuals)
qqline(modelo2$residuals)
```

En definitiva, parece un problema de outliers. Sin embargo:

```{r}
shapiro.test(modelo2$residuals)
```
Mas llevados. Por tal motivo, nos hacemos los de la marcha LGTBI* y seguimos adelante con este modelo. 

Hay dos posibilidades: 
 
 1) Hacer intervencion para dictaminar que mejoras pueden haber al hacer un analisis de outliers
 
 2) Borre esos datos de la serie, modele sin los datos que le estan dañando el modelo y devuelva el titulo de estadistico. 


Para este caso, se prosigue a graficar el modelo, la serie de test y finalmente, se predice.

```{r}
# prediccion HW

f_fit <- y_hat1

autoplot(dftimeserie, series="Datos") + 
   autolayer(mod1$fitted, series="Modelo auto.arima fitted ") +
   autolayer(f_fit, series="Prediction") +
   #autolayer()+
   xlab("Year") + ylab("Total sacrificios (1/100.000)") + ggtitle("Total de sacrifios 2008-2022") + theme_bw()+theme(legend.title = element_blank(),legend.position = "bottom")

```

En el grafico anterior, se tiene los datos en rojo, los ajustados por el modelo HW en verde u finalmente la predicción a los datos de prueba. para los datos de prueba. No se grafica el IC dado que puede ser caótico para visualizar. Ahora, dicho grafico seria:

```{r echo=FALSE}
f_fit <- forecast(mod1,h=34)
autoplot(dftimeserie, series="Datos") + 
   #autolayer(mod4$fitted, series="Modelo auto.arima fitted ") +
   autolayer(f_fit, series="Prediction (Test)") +
   #autolayer()+
   xlab("Year") + ylab("Total sacrificios (1/100.000)") + ggtitle("Total de sacrifios 2008-2022") + theme_bw()+theme(legend.title = element_blank(),legend.position = "bottom")

```

Ahora, acá se tienen los datos reales en rojo y solo la predicción. Note como el modelo tiene peor rendimiento que cuando se ajusta con la totalidad de la base de datos. Sin embargo, el ajuste de la serie predicha por el modelo no es necesariamente malo. Ahora, recuerde que entre más predicciones en el tiempo se hagan, más imprecisa es la predicción. 

Predicciones Noviembre octubre 2022- Julio 2023

```{r}
f_fit %>% kable()
```


## Prediccion modelo elegido

Finalmente, con el arima que arroja la funcion auto.arima -ARIMA(3,0,0)(0,1,2)[12]-; se procede a predecir finalmente los valores asociados a el siguiente año. La prediccion seria tal que:

```{r echo=FALSE}
modelo.final = Arima(dftimeserie, order = c(3,0,0),seasonal = c(0,1,2))

f_fit <- forecast(modelo.final,h=12)

autoplot(ts(df2$t_cabezas, frequency = 12), series="Datos") + 
   autolayer(modelo.final$fitted, series="Modelo auto.arima fitted ") +
   autolayer(f_fit, series="Prediction (Test)") +
   #autolayer()+
   xlab("Year") + ylab("Total sacrificios (1/100.000)") + ggtitle("Total de sacrifios 2008-2022") + theme_bw()+theme(legend.title = element_blank(),legend.position = "bottom")
```

```{r echo=FALSE}
modelo.final = Arima(dftimeserie, order = c(3,0,0),seasonal = c(0,1,2))
f_fit <- forecast(modelo.final)
 autoplot(dftimeserie, series="Datos") + 
   autolayer(modelo.final$fitted, series="SARIMA(3,0,0)(0,1,2)[12] ") +
   autolayer(f_fit, series="Prediction") +
   xlab("Year") + ylab("Total sacrificios (1/100.000)") + ggtitle("Total de sacrifios 2008-2022") + theme_bw()+theme(legend.title = element_blank(),legend.position = "bottom")
```



## Análisis de outliers

Observe de nuevo la serie original. Con esta serie se busca entonces entender si existe un comportamiento de datos atípicos. Ahora, note que:


```{r echo=FALSE}
plot(dftimeserie)
```

De manera descriptiva se observa que para el año 2020 se tiene una caída más pronunciada. Se desea observar si para dicho dato existe evidencia de ser un outlier.

La función tso del paquete tsoutliers permite analizar los datos atípicos de una serie de tiempo. 

*Modelo de Outliers*


```{r}
mod_outliers <- tso(dftimeserie, delta=0.7)

mod_outliers 
```

Por defecto, el modelo de los outliers deja fijado un delta de 0.7.

ARIMA(1,0,1)(0,1,0)[12] es el modelo resultante despues de aplicar la funcion. Ademas, se detectan tres outliers de tipo AO, lo que implica que son datos que afectaron la serie de manera puntual en ese punto. 

Las fechas son las que aparecen en la tabla anterior y su respectivo indice.  Este dato coincide con Marzo del 2020, en cual se declara pandemia. Por este motivo, se podría esperar que la observación 139 sea un dato atípico AO, es decir; afectó momentáneamente la serie de tiempo y luego esta se normalizó. Por tal motivo se concluye que se ha de modelar con una función pulso. Los demas puntos no selogran asociar a causas asignables de manera inmediata. Se podria sospechar, efectos despues de la pandemia, paro, etc.  


## Intervención

Se procede a dividir la serie antes de la intervención. Esto se selecciona basado en una idea muy simple; posiblemente la pandemia pudo afectar el número de sacrificios mensuales. En la serie, es el dato 139 el cual corresponde a marzo del 2020 (donde se evidencia la caída).


```{r echo=FALSE}
ensayointervencio <- window(dftimeserie, start=time(dftimeserie)[1],
                end = time(dftimeserie)[138])
paco = ensayointervencio %>% auto.arima(stepwise = F,approximation = F) 
paco %>% summary()
```

Finalmente, se tiene que los órdenes del modelo con auto.arima; así pues, se tiene un ARIMA(3,0,0)(0,1,2)[12]; para un modelo ajustado antes de la intervención. 

Entonces, este es el modelo con la intervención a la observación 139.

## *Función pulso:*


```{r}
modelo1superintervencion <- arimax(dftimeserie, order=c(3, 0, 0),seasonal = list(order = c(0, 1, 2)),
xtransf=data.frame( creemosquepandemia=1 *(seq_along(dftimeserie) == 139)),
transfer=list(c(1, 0)))
modelo1superintervencion %>% coeftest()
```

Dada esta tabla, se busca entender cuál de los coeficientes son o no significativos. 

Entonces, como el AR1 NO es significativo; se concluye que la función a utilizar es una función pulso. Dicho de otra manera (Mas bonita):

El δ1 estimado (0.034201x100.000 =3420.1 ) no es significativo con un nivel de significancia del 5 %. En cambio, el ω1 estimado (-0.692464x100000=-69246.4 ) sí es significativo; lo que implica que la caída dada por pandemia es de cerca de 69246 cabezas de marranos.

En pocas palabras, la pandemia afectó en promedio la producción de cabezas porcinas en casi 70 mil unidades menos de lo que se producía normalmente.


```{r}
modelo1superintervencion2 <- arimax(dftimeserie, order=c(3, 0, 0),seasonal = list(order = c(0, 1, 2)),
xtransf=data.frame( creemosquepandemia=1 *(seq_along(dftimeserie) == 139)),

transfer=list(c(0, 0)))
modelo1superintervencion2 %>% coeftest()
```

Finalmente, al analizar los datos realizando la intervención, se concluye que el modelo es significativo en todos sus parámetros entonces; se procede a predecir con dicho modelo intervenido.

## Predicción con modelo intervenido. 

Para realizar las predicciones con el modelo intervenido, se ha de revisar los supuestos del modelo. Entonces:

```{r}
modelo1superintervencion2 %>% checkresiduals()
```

Al analizar de manera descriptiva, el modelo parece seguir una distribución normal, la ACF detecta autocorrelación y, parece que los errores tienen problemas de autocorrelación.

Respecto a outliers, se detectan algunos puntos marcados, pero no tienen asociados causas asignables.

Varianza constante (en principio); Por otra parte, se observa que la prueba de correlación de los residuales de Ljung-Box determina correlación en los residuales. 

Aun así, dada las condiciones del modelo se decide *NO* intervenir nuevamente, puesto que se podría sobre ajustar. 

*Normalidad residuales: *


```{r echo=FALSE}
modelo1superintervencion2$residuals %>% shapiro.test()
```
Note que, aunque así lo parezca; los errores según la prueba de Shapiro-Wilk no son normales. Se procede a analizar el QQ-plot.
```{r echo=FALSE}
qqnorm(modelo1superintervencion2$residuals)
qqline(modelo1superintervencion2$residuals)
```

Note que los residuales tienen en general un buen ajuste a la recta de normalidad. El QQ-plot tiene algunos datos atípicos. 

## Predicciones con modelo intervenido

Finalmente, se procede a realizar las predicciones con el modelo intervenido.

A continuación se muestra el modelo intervenido.

```{r echo=FALSE}
modelo1superintervencion2
```

```{r}

reg1 <- stats::filter(1 * (seq.int(length(dftimeserie) + 12)== 139),

filter =0, method = "rec",
sides = 1)
xreg <- cbind(I1=stats::filter(1*(seq_along(dftimeserie) == 139),method = "rec",sides = 1,filter = 0))

modelo_intervenido <-arima(dftimeserie, order = c(3,0, 0),
seasonal = list(order = c(0,1,2),
period = 12), xreg = xreg)
```

```{r}
modelo_intervenido %>% coeftest()
```
Note que para cada parametro del modelo, se tiene que son significativos.

```{r message=FALSE, warning=FALSE}
df2$t_cabezas=df2$t_cabezas
vectores <- c(df2$t_cabezas)
dftimeserie <-ts(vectores, frequency = 12, start = c(2008,10))
reg1 <- ts(reg1, start = start(dftimeserie),
frequency = frequency(dftimeserie)) # hasta aca se tiene 0 y 1 en la intervencion
reg1_new <- window(reg1, start = c(2022,09), end = c(2023,08))

inter.pred = predict(modelo_intervenido, newxreg=reg1_new, n.ahead=12)
inter.pred # Estas son las predicciones
```

```{r}
prediccions = inter.pred$pred # serie de tiempo de la prediccion
se = inter.pred$se # para crear los IC
```

```{r}
#MSE = mean((df2$t_cabezas- fitted.values(modelo_intervenido)))^2
#MSE
```
El MSE de este modelo es del orden de 0.000007387; Hasta el momento, ningún modelo ha ajustado un MSE tan pequeño.
De esta manera, este modelo con intervenciones; parece el modelo más confiable para realizar predicciones.

## Grafica de la predicción


```{r}
serie.original = df2$t_cabezas
prediccions = as.data.frame(prediccions)
s1 = df2$t_cabezas # termina en septiembre del 2022
s2 = prediccions #

a1 = ts(s1, frequency = 12, start = c(2008,10))
a2 = ts(s2, frequency = 12, start = c(2022,09))

#Visually evaluate the prediction
autoplot(a1, series="Datos") + 
   autolayer(a2, series="Predicciones") +
   #autolayer(HW2.pred, series="Prediction") +
   xlab("Year") + ylab("Total sacrificios (1/100.000)") + ggtitle("Total de sacrifios 2008-2022") + theme_bw()+theme(legend.title = element_blank(),legend.position = "bottom")
```

Finalmente, se tienen las predicciones con su respectivo IC.



































Referencias:

 Los maricas*